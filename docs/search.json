[
  {
    "objectID": "TrueNTH.html",
    "href": "TrueNTH.html",
    "title": "TrueNTH Results",
    "section": "",
    "text": "This report contains all code used in the analysis and the output of the results and was created using R 4.1.2 (R Core Team, 2021) with RMarkdown. (Allaire et al., 2022; Xie et al., 2018, 2020) Several R packages were used. (Gagolewski, 2021; Gohel and Skintzos, 2023; Harrell Jr, 2022; Henry and Wickham, 2023; Heymans, 2022; Hofmann et al., 2022; Honaker et al., 2011; Ooms, 2022; Pedersen, 2022; Pedersen and Robinson, 2022; Robitzsch and Grund, 2022; van Buuren and Groothuis-Oudshoorn, 2011; Wickham, 2016; Wickham et al., 2022; Xie, 2014; Zhu, 2021)\n\nCodeset.seed(1)\noptions(digits=2)\nlibrary(rlang)\nlibrary(dplyr) \nlibrary(knitr)\nlibrary(ggplot2)\nlibrary(Hmisc)\nlibrary(ggpcp)\nlibrary(Amelia)\nlibrary(mice)\nlibrary(miceadds)\nlibrary(stringi)\nlibrary(miceafter)\nlibrary(patchwork)\nlibrary(flextable)\nlibrary(gganimate)\nlibrary(gifski)\nlibrary(stringr)\nlibrary(ggsci)\nlibrary(dataMeta)\nlibrary(DT)\nset_flextable_defaults(\n  na_str=\"Unknown\",\n  nan_str=\"Unknown\",\n)\nload(file=\"misc_files/helpers.RData\") # Some helper functions are saved in an RData file\n\nl = readRDS(\"misc_files/TrueNTHLong.rds\")\nw = readRDS(\"misc_files/TrueNTHWide.rds\")\n\n\nEPIC-26\nEPIC-26, a short form-version of the Expanded Prostate Cancer Index Composite (EPIC), was used to collect participant reported outcome measures (PROMs). (Wei et al., 2000) We were mainly interested in the urinary incontinence and sexual function domains as these were identified as important by participants feedback.\n\n\nUrinary incontinence\nSexual function\nDomain scores\n\n\n\nThe urinary incontinence domain has four questions (EPIC-26 questions 23, 26, 27 and 28)\n\nOver the past 4 weeks, how often have you leaked urine?\nWhich of the following best describes your control during the last 4 weeks?\nHow many pads or adult diapers per day did you usually use to control leakage during the last 4 weeks?\nHow big a problem, if any, has each of the following been for you during the last 4 weeks? Dripping or leaking urine\n\n\n\nThe sexual function has six questions (EPIC-26 questions 57, 58, 59, 60, 64, and 68)\n\nHow would you rate each of the following during the last 4 weeks? Your ability to have an erection\nHow would you rate each of the following during the last 4 weeks? Your ability to reach orgasm (climax)\nHow would you describe the usual quality of your erections during the last 4 weeks?\nHow would you describe the frequency of your erections during the last 4 weeks?\nOverall, how would you rate your ability to function sexually during the last 4 weeks?\nOverall, how big a problem has your sexual function or lack of sexual function been for you during the last 4 weeks?\n\n\n\nThe responses are given a numerical value based on a scale for 0 to 100, according to the EPIC scoring criteria. The mean of these values can be calculated to obtain a domain score. The score calculation allows up-to 20% missing data according to the scoring criteria; this means that the urinary incontinence domain score must have all questions answered, whereas the sexual function domain score may have one missing question. (Wei et al., 2000)\n\n\n\nData\nThe .csv files extracted from the records consist of\n\nPROM reports named Phase X Y.csv where X is either “1” or “2” and Y is one of “baseline”, “Month 1”, “Month 3”, “Month 6”, “Month 12”\nPatient demographics in “Patient Demographics.csv”\nClinical data in “BAUS.csv”\nInformation on participant consent in “Consent.csv”\nMapping of hospital ID in “BAUS.csv” to the hospital name\n\n\n\nPreprocessing\nTotal number of participants\nComplete case data\n\n\n\nThe PROMs were in long format and needed to be converted to wide format (by question) and then concatenated. This resulted in them being in long format by time point. The study IDs were then checked in the consent file to double check that only consented participants were included. Finally, the age at surgery was calculated for each participant using the date of birth and date of surgery. If either the date of birth or date of surgery were missing, then the age was treated as missing data.\nFrom this, the EPIC-26 domain scores needed to be calculated by converting the responses into values and calculating the mean. This follows the EPIC-26 guidance. The urinary incontinence score and sexual function score were calculated according to the EPIC-26 scoring instructions. (Wei et al., 2000)\nSome participants also reported baseline clinical variables (e.g., PSA, Gleason score, nerve sparing approach used, and D’Amico risk classification). The clinical data was contained in another file and needed to be added to the dataset.\nThis then created a dataset in wide format. Phase (1 or 2) is the study phase, time 0 is baseline and the other times (1, 3, 6, 12) are months, study IDs are the anonymised IDs, DoB and DoS are the date of birth and date of surgery, respectively.\nHeadings starting with A are answers and headings starting with C are coded answers. The heading numbers for refer to the original EPIC question numbers. For example, A23 is the answer for EPIC question 23 (EPIC-26 question 1) and C23 is the coded answer (0, 25, 50, 75, 100) which was used to calculate the domain score.\nThe headings Umiss and Smiss show how many items are missing from the urinary (incontinence) and sexual (function) domains, respectively. The urinary domain allows no missing items, while the sexual domain allows 1 missing item. Uscore and Sscore are the urinary (incontinence) and sexual (function) domain scores; these are calculated as the mean of the coded items.(Wei et al., 2000)\n\n\nA total of 2,030 participants were used in the final analysis, with 1,118 of those reporting clinical variables. The table below summarises the participant numbers.\n\nCode# Count the number of participants\ndf_ccN = data.frame(\"Set\"=c(\n  \"Full analytical cohort\",\n  \"PROM and clinical data\",\n  \"PROM data only\"\n  ),\n  \"Number\"=c(\n    n_distinct(l[\"Study_ID\"]),\n     sum(w$Clinical_data),\n    sum(abs(1-w$Clinical_data))\n  ))\ntab = flextable(df_ccN)\nggplot()+\n  gen_grob(tab)+\n  plot_layout(nrow=2,heights=c(0,1))\n\n\n\n\n\n\nWe analyse the participants with complete baseline and 12 month urinary and complete baseline and 12 month sexual function data, separately. Here, the participants with complete urinary incontinence and sexual function data at baseline and 12 months are extracted and stored as separate data frames.\nThe number of participants with full baseline and 12 month data for urinary incontinence and sexual function outcomes is shown in the table below.\n\nCode# How many of the participants have complete data \nub = w[w$Umiss.0==0 & !is.na(w$Umiss.0),] # Number with complete urinary data at baseline\nuf = w[w$Umiss.12==0 & !is.na(w$Umiss.12),] # Number with complete urinary data at 12 months\nsb = w[w$Smiss.0==0 & !is.na(w$Assist.0) & !is.na(w$Smiss.0),] # Number with complete sexual data at baseline\nsf = w[w$Smiss.12==0 & !is.na(w$Assist.12) & !is.na(w$Smiss.12),] # Number with complete sexual data at 12 months\nuf = uf %&gt;% filter(Study_ID %in% unique(ub$Study_ID)) # Number with complete urinary data at baseline and 12 months\nsf = sf %&gt;% filter(Study_ID %in% unique(sb$Study_ID)) # Number with complete sexual data at baseline and 12 months\n\ndf_ccN = data.frame(\"Set\"=c(\n  \"Full urinary incontinence data at baseline\",\n  \"Full urinary incontinence data at baseline and 12 months\",\n  \"Full sexual function data at baseline\",\n  \"Full sexual function data at baseline and 12 months\"\n  ),\n  \"Number\"=c(\n    length(ub$Study_ID),\n    length(uf$Study_ID),\n    length(sb$Study_ID),\n    length(sf$Study_ID)\n  ))\ntab=flextable(df_ccN)\nggplot()+\n  gen_grob(tab)+\n  plot_layout(nrow=2,heights=c(0,1))\n\n\n\n\n\n\n\nBaseline characteristics\nHere, we present the baseline characteristics for the PROM participants. “Missing” or “NA” indicates the number of missing responses. These are for all participants and missing data is reported. These values were used in constructing Table 2 in the manuscript.\nBaseline characteristics are reported for all participants, participants with PROM data only, and PROM with clinical data participants separately. For this, the participants first need to be split into these groups and stored as data frames.\n\nCode# w is the data frame with all participants\nprom = w[w$Clinical_data==0,] # PROM only\npromwc = w[w$Clinical_data==1,] # PROM with clinical data\n\n\n\n\nAges\nYear of surgery\nEthnicities\nMarital status\nComorbidities\nUrinary\nSexual\nClinical variables\nSurgeons and centres\n\n\n\nThe ages of participants at surgery time were calculated using the date of birth and date of surgery. Any date of births before 1900 and after 2000, were assumed to be entered incorrectly as these participants would not be candidates for surgery. Any surgery dates before 2015 were also assumed to be entered incorrectly as all surgeries were carried out after 2015. These values were deemed to be missing.\n\n\nAll\nPROM and clinical data\nPROM data only\n\n\n\nAges ranged from 36 to 83, with a mean of 64.7 years, with 73 missing ages.\n\nCode# Table of the summary data\nsum_tab(w$Age)\n\n\n\n\nThe frequencies of ages in different age categories are given in the table below with a histogram shown.\n\nCodehist_age(w$Age, xlab='Range', ylab='Count')\n\n\n\n\n\n\nAges range from 40 to 79 with a median age of 64.3. There are 17 missing ages.\n\nCodesum_tab(promwc$Age)\n\n\n\n\nThe frequencies of ages in different age categories are given in the table below with a histogram shown.\n\nCodehist_age(promwc$Age, xlab='Age', ylab='Count')\n\n\n\n\n\n\nAges range from 36 to 83 with a mean of 64.2. There are 56 missing ages.\n\nCodesum_tab(prom$Age)\n\n\n\n\nThe frequencies of ages in different age categories are given in the table below with a histogram shown.\n\nCodehist_age(prom$Age, xlab='Range', ylab='Count')\n\n\n\n\n\n\n\n\n\nHere, we present the years that the surgeries were performed.\n\n\nAll\nPROM and clinical\nPROM only\n\n\n\nFor all 2030 participants, the years of surgery are shown in the bar plot and table below.\n\nCodeyears = format(as.Date(w$DoS), format=\"%Y\")\nbar_tab(years, xlab = \"Year of surgery\", ylab = \"Count\")\n\n\n\n\n\n\nFor the participants with clinical and PROM data, the years of surgery are shown in the bar plot and table below.\n\nCodeyears = format(as.Date(promwc$DoS), format=\"%Y\")\nbar_tab(years, xlab = \"Year of surgery\", ylab = \"Count\")\n\n\n\n\n\n\nFor the participants with PROM data only, the years of surgery are shown in the bar plot and table below.\n\nCodeyears = format(as.Date(prom$DoS), format=\"%Y\")\nbar_tab(years, xlab = \"Year of surgery\", ylab = \"Count\")\n\n\n\n\n\n\n\n\n\n\n\nAll\nPROM and clinical\nPROM only\n\n\n\nA table of the frequencies of reported ethnicities for all participants is shown below.\n\nCodetab = proc_freq(w, \"Race.0\")\ntab = set_header_labels(tab, Race.0=\"Race\", Count=\"Number of participants\")\ntab\n\n\n\n\n\n\nRace\nCount\nPercent\n\n\n\n White and Asian \n5\n0.2%\n\n\nAfrican\n44\n2.2%\n\n\nAny other Asian background\n7\n0.3%\n\n\nAny other Black / African / Caribbean background\n7\n0.3%\n\n\nAny other ethnic group\n9\n0.4%\n\n\nAny other Mixed / Multiple ethnic background\n6\n0.3%\n\n\nAny other White background\n45\n2.2%\n\n\nArab\n4\n0.2%\n\n\nBangladeshi \n1\n0.0%\n\n\nCaribbean\n39\n1.9%\n\n\nChinese \n5\n0.2%\n\n\nEnglish / Welsh / Scottish / Northern Irish / British \n1,776\n87.5%\n\n\nIndian\n22\n1.1%\n\n\nIrish\n31\n1.5%\n\n\nPakistani\n7\n0.3%\n\n\nWhite and Black African\n9\n0.4%\n\n\nWhite and Black Caribbean\n5\n0.2%\n\n\nMissing\n8\n0.4%\n\n\nTotal\n2,030\n100.0%\n\n\n\n\n\n\n\n\nA table of the frequencies of reported ethnicities for participants with clinical data available is shown below.\n\nCodetab = proc_freq(promwc, \"Race.0\")\ntab = set_header_labels(tab, Race.0=\"Race\", Count=\"Number of participants\")\ntab\n\n\n\n\n\n\nRace\nCount\nPercent\n\n\n\n White and Asian \n3\n0.3%\n\n\nAfrican\n32\n2.9%\n\n\nAny other Asian background\n7\n0.6%\n\n\nAny other Black / African / Caribbean background\n5\n0.4%\n\n\nAny other ethnic group\n7\n0.6%\n\n\nAny other Mixed / Multiple ethnic background\n2\n0.2%\n\n\nAny other White background\n33\n3.0%\n\n\nArab\n2\n0.2%\n\n\nBangladeshi \n1\n0.1%\n\n\nCaribbean\n27\n2.4%\n\n\nChinese \n2\n0.2%\n\n\nEnglish / Welsh / Scottish / Northern Irish / British \n948\n84.8%\n\n\nIndian\n13\n1.2%\n\n\nIrish\n19\n1.7%\n\n\nPakistani\n4\n0.4%\n\n\nWhite and Black African\n6\n0.5%\n\n\nWhite and Black Caribbean\n4\n0.4%\n\n\nMissing\n3\n0.3%\n\n\nTotal\n1,118\n100.0%\n\n\n\n\n\n\n\n\nA table of the frequencies of reported ethnicities for participants with no clinical data available is shown below.\n\nCodetab = proc_freq(prom, \"Race.0\")\ntab = set_header_labels(tab, Race.0=\"Race\", Count=\"Number of participants\")\ntab\n\n\n\n\n\n\nRace\nCount\nPercent\n\n\n\n White and Asian \n2\n0.2%\n\n\nAfrican\n12\n1.3%\n\n\nAny other Black / African / Caribbean background\n2\n0.2%\n\n\nAny other ethnic group\n2\n0.2%\n\n\nAny other Mixed / Multiple ethnic background\n4\n0.4%\n\n\nAny other White background\n12\n1.3%\n\n\nArab\n2\n0.2%\n\n\nCaribbean\n12\n1.3%\n\n\nChinese \n3\n0.3%\n\n\nEnglish / Welsh / Scottish / Northern Irish / British \n828\n90.8%\n\n\nIndian\n9\n1.0%\n\n\nIrish\n12\n1.3%\n\n\nPakistani\n3\n0.3%\n\n\nWhite and Black African\n3\n0.3%\n\n\nWhite and Black Caribbean\n1\n0.1%\n\n\nMissing\n5\n0.5%\n\n\nTotal\n912\n100.0%\n\n\n\n\n\n\n\n\n\n\n\n\n\nAll\nPROM and clinical\nPROM\n\n\n\nFor all participants, the number reporting marital status is shown below.\n\nCodetab = proc_freq(w, \"Marital.0\")\ntab = set_header_labels(tab, Marital.0=\"Marital status\", Count=\"Number of participants\")\ntab\n\n\n\n\n\n\nMarital status\nCount\nPercent\n\n\n\nIn a significant relationship, but not living together\n93\n4.6%\n\n\nMarried or living with a partner\n1,749\n86.2%\n\n\nOther\n18\n0.9%\n\n\nSingle / living alone\n133\n6.6%\n\n\nSingle / not living alone\n22\n1.1%\n\n\nMissing\n15\n0.7%\n\n\nTotal\n2,030\n100.0%\n\n\n\n\n\n\n\n\nFor participants with PROM and clinical data, the number reporting marital status is shown below.\n\nCodetab = proc_freq(promwc, \"Marital.0\")\ntab = set_header_labels(tab, Marital.0=\"Marital status\", Count=\"Number of participants\")\ntab\n\n\n\n\n\n\nMarital status\nCount\nPercent\n\n\n\nIn a significant relationship, but not living together\n54\n4.8%\n\n\nMarried or living with a partner\n954\n85.3%\n\n\nOther\n11\n1.0%\n\n\nSingle / living alone\n76\n6.8%\n\n\nSingle / not living alone\n16\n1.4%\n\n\nMissing\n7\n0.6%\n\n\nTotal\n1,118\n100.0%\n\n\n\n\n\n\n\n\nFor participants with PROM data only, the number reporting marital status is shown below.s\n\nCodetab = proc_freq(prom, \"Marital.0\")\ntab = set_header_labels(tab, Marital.0=\"Marital status\", Count=\"Number of participants\")\ntab \n\n\n\n\n\n\nMarital status\nCount\nPercent\n\n\n\nIn a significant relationship, but not living together\n39\n4.3%\n\n\nMarried or living with a partner\n795\n87.2%\n\n\nOther\n7\n0.8%\n\n\nSingle / living alone\n57\n6.2%\n\n\nSingle / not living alone\n6\n0.7%\n\n\nMissing\n8\n0.9%\n\n\nTotal\n912\n100.0%\n\n\n\n\n\n\n\n\n\n\n\nThere were two categories for diabetes: “Diabetes” and “Diabetes”. One of them had a white space making it recognised as a separate category. As there was no option for “no diabetes”, it is impossible to distinguish between participants without diabetes and participants with missing data.\n\n\nAll\nPROM and clinical\nPROM\n\n\n\nThe number of participants reporting diabetes and heart disease among all participants is shown below.\n\nCodetable(w$Diabetes.0)\n\n\n Diabetes Diabetes  \n       28       108 \n\nCodetable(w$HeartD.0)\n\n\nHeart disease (for example angina, heart attack or heart failure) \n                                                               99 \n\n\n\n\nFor those with PROM and clinical data, the number reporting diabetes and heart disease is shown below.\n\nCodetable(promwc$Diabetes.0)\n\n\n Diabetes Diabetes  \n       16        60 \n\nCodetable(promwc$HeartD.0)\n\n\nHeart disease (for example angina, heart attack or heart failure) \n                                                               45 \n\n\n\n\nFor those with PROM data only, the number reporting diabetes and heart disease is shown below.\n\nCodetable(prom$Diabetes.0)\n\n\n Diabetes Diabetes  \n       12        48 \n\nCodetable(prom$HeartD.0)\n\n\nHeart disease (for example angina, heart attack or heart failure) \n                                                               54 \n\n\n\n\n\n\n\nHere, we show the reported baseline leakage (EPIC question 23) and pad use (EPIC question 27).(Wei et al., 2000)\n\n\nAll\nPROM and clinical\nPROM only\n\n\n\nHere are the results for all participants in the analytical cohort.\n\n\nLeakage\nPad use\nLeakage and pad use\nUrinary score\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine?\n\nCodebar_tab(w$A23.0, xlab=\"Leakage\", \"Count\")\n\n\n\n\n\n\nQ27: How many pads per day did you usually use to control leakage during the last 4 weeks?\n\nCodebar_tab(w$A27.0, xlab=\"Pad use\", \"Count\")\n\n\n\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine? AND Q27: How many pads per day did you usually use to control leakage during the last 4 weeks?\n\nCodebar_tab2(w$A23.0, w$A27.0, \"Leakage\", \"Count\", \"Pad use\")\n\n\n\n\n\n\nThe number reporting all four urinary incontinence domain responses to calculate the urinary incontinence score was\n\nCodeas.numeric(colSums(!is.na(w[\"Uscore.0\"])))\n\n[1] 1996\n\n\nThe median and interquartile range among these participants was\n\nCodequantile(w[\"Uscore.0\"], c(.25, .5, .75), na.rm=T)\n\n25% 50% 75% \n 86 100 100 \n\n\n\n\n\n\n\nHere are the results for the participants who had clinical data available.\n\n\nLeakage\nPad use\nLeakage and pad use\nUrinary score\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine?\n\nCodebar_tab(promwc$A23.0, xlab=\"Leakage\", \"Count\")\n\n\n\n\n\n\nQ27: How many pads per day did you usually use to control leakage during the last 4 weeks?\n\nCodebar_tab(promwc$A27.0, xlab=\"Pad use\", \"Count\")\n\n\n\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine? AND Q27: How many pads per day did you usually use to control leakage during the last 4 weeks?\n\nCodebar_tab2(promwc$A23.0, promwc$A27.0, \"Leakage\", \"Count\", \"Pad use\")\n\n\n\n\n\n\nFor participants with PROM and clinical data, the number reporting all four urinary incontinence domain responses to calculate the urinary incontinence score was\n\nCodeas.numeric(colSums(!is.na(promwc[\"Uscore.0\"])))\n\n[1] 1100\n\n\nThe median and interquartile range of the urinary incontinence score for these participants was\n\nCodequantile(promwc[\"Uscore.0\"], c(.25, .5, .75), na.rm=T)\n\n25% 50% 75% \n 86 100 100 \n\n\n\n\n\n\n\nHere are the results for participants who did not have clinical data available.\n\n\nLeakage\nPad use\nLeakage and pad use\nUrinary score\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine?\n\nCodebar_tab(prom$A23.0, xlab=\"Leakage\", \"Count\")\n\n\n\n\n\n\nQ27: How many pads per day did you usually use to control leakage during the last 4 weeks?\n\nCodebar_tab(prom$A27.0, xlab=\"Pad use\", \"Count\")\n\n\n\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine? AND Q27: How many pads per day did you usually use to control leakage during the last 4 weeks?\n\nCodebar_tab2(prom$A23.0, prom$A27.0, \"Leakage\", \"Count\", \"Pad use\")\n\n\n\n\n\n\nFor participants with PROM data only, the number with all four urinary incontinence domain responses to calculate the urinary incontinence score was\n\nCodeas.numeric(colSums(!is.na(prom[\"Uscore.0\"])))\n\n[1] 896\n\n\nThe median and interquartile range of the urinary incontinence score for these participants was\n\nCodequantile(prom[\"Uscore.0\"], c(.25, .5, .75), na.rm=T)\n\n25% 50% 75% \n 86 100 100 \n\n\n\n\n\n\n\n\n\n\nHere, we show the reported baseline leakage (EPIC question 59) and whether the participant used medication or devices to improve erections (this question is not included in EPIC).(Wei et al., 2000)\n\n\nAll\nPROM and clinical\nPROM only\n\n\n\n\n\nQuality\nAssistance\nScore\n\n\n\nQ59: How would you describe the usual QUALITY of your erections during the last 4 weeks? AND Have you used any medications or devices to aid or improve erections?\n\nCodebar_tab2(w$A59.0, w$Assist.0, \"Erection\", \"Count\", \"Assistance\")\n\n\n\n\n\n\nHere, we present the responses for specific assistance use.\n\nCodeassist_use(w, 0)\n\n\n\n\n\n\nAmong all participants, the number with sufficient PROMs to calculate the sexual function score was\n\nCodeas.numeric(colSums(!is.na(w[\"Sscore.0\"])))\n\n[1] 1953\n\n\nThe median score and interquartile range for these participants was\n\nCodequantile(w[\"Sscore.0\"], c(.25, .5, .75), na.rm=T)\n\n25% 50% 75% \n 42  71  92 \n\n\n\n\n\n\n\n\n\nQuality\nAssistance\nScore\n\n\n\nQ59: How would you describe the usual QUALITY of your erections during the last 4 weeks? AND Have you used any medications or devices to aid or improve erections?\n\nCodebar_tab2(promwc$A59.0, promwc$Assist.0, \"Erection\", \"Count\", \"Assistance\")\n\n\n\n\n\n\nHere, we present the responses for specific assistance use.\n\nCodeassist_use(promwc, 0)\n\n\n\n\n\n\nFor participants with PROM and clinical data, the number with sufficient PROMs to calculate the sexual function score was\n\nCodeas.numeric(colSums(!is.na(promwc[\"Sscore.0\"])))\n\n[1] 1079\n\n\nThe median score and interquartile range for these participants was\n\nCodequantile(promwc[\"Sscore.0\"], c(.25, .5, .75), na.rm=T)\n\n25% 50% 75% \n 44  75  92 \n\n\n\n\n\n\n\n\n\nQuality\nAssistance\nScore\n\n\n\nQ59: How would you describe the usual QUALITY of your erections during the last 4 weeks? AND Have you used any medications or devices to aid or improve erections?\n\nCodebar_tab2(prom$A59.0, prom$Assist.0, \"Erection\", \"Count\", \"Assistance\")\n\n\n\n\n\n\nHere, we present the responses for specific assistance use.\n\nCodeassist_use(prom, 0)\n\n\n\n\n\n\nFor participants with PROM data only, the number with sufficient PROMs to calculate the sexual function score was\n\nCodeas.numeric(colSums(!is.na(prom[\"Sscore.0\"])))\n\n[1] 874\n\n\nThe median score and interquartile range for these participants was\n\nCodequantile(prom[\"Sscore.0\"], c(.25, .5, .75), na.rm=T)\n\n25% 50% 75% \n 39  70  92 \n\n\n\n\n\n\n\n\n\n\nThese are for the participants with PROMs and clinical data only.\n\n\nPSA\nGleason score\nNerve sparing approach\nLymphadenectomy\nD’Amico\nSurgical approach\n\n\n\nReported PSAs sorted into categories are shown in the table and bar chart below.\n\nCodetab = cut(as.numeric(promwc$PSA), c(0,10, 20.00001, 100000000), right=F)\nlevels(tab)=c(\n  \"0 to less than 10\",\n  \"10 to less than 20\",\n  \"Over 20\"\n  )\nbar_tab(tab, xlab=\"PSA\", ylab=\"count\")\n\n\n\n\n\n\nReported Gleason scores are shown in the table and bar chart below. In the graph, “other” is grouped with missing.\n\nCodebar_tab(promwc$GS, xlab=\"Gleason Score\", ylab=\"Count\")\n\n\n\n\nFor this, other was counted as unknown.\n\n\nReported nerve sparing approaches are shown in the table and bar chart below.\n\nCodebar_tab(promwc$NSA, xlab=\"Nerve Sparing Approach\", ylab=\"Count\")\n\n\n\n\n\n\nReported lymphadenectomies are shown in the table and bar chart below.\n\nCodebar_tab(promwc$Lymph, xlab = \"Lymphadenectomy\", ylab=\"Count\")\n\n\n\n\n\n\nReported D’Amico categories are shown in the table and bar chart below.\n\nCodebar_tab(promwc$DAmico, \"D'Amico risk\", \"Count\")\n\n\n\n\n\n\n\nCodebar_tab(promwc$Approach, \"Surgical approach\", \"Count\")\n\n\n\n\n\n\n\n\n\n\n\nSurgeons\nCentres\n\n\n\nThere were 587 missing values which have been removed to make the graph easier to read. One of the categories shown here is “other” and may include more than one surgeon.\n\nCodebar_tab(w$Surgeon[complete.cases(w$Surgeon)], \"Surgeon\", \"Count\")\n\n\n\n\n\n\n\nCodebar_tab(w$Hospital_ID.0, \"Centre\", \"Count\")\n\n\n\n\n\n\n\n\n\n\nHistograms of domain scores\nHistograms showing the distributions of urinary incontinence and sexual function domain scores for each of the time points are shown in this section.\n\n\nUrinary score\nSexual score\n\n\n\n\n\nBaseline\nMonth 1\nMonth 3\nMonth 6\nMonth 12\n\n\n\nThe median and interquartile range among the 1,996 participants with sufficient responses to calculate the domain score is\n\nCodequantile(w[\"Uscore.0\"], c(.25, .5, .75), na.rm=T)\n\n25% 50% 75% \n 86 100 100 \n\n\nA histogram of the available scores at baseline is shown below.\n\nCodehist(unlist(w[\"Uscore.0\"]), main=\"Histogram of urinary incontinence scores at baseline\", xlab=\"Score\")\n\n\n\n\n\n\nThe median and interquartile range among the 1,415 participants with sufficient responses to calculate the domain score is\n\nCodequantile(w[\"Uscore.1\"], c(.25, .5, .75), na.rm=T)\n\n25% 50% 75% \n 27  50  65 \n\n\nA histogram of the available scores shown below.\n\nCodehist(unlist(w[\"Uscore.1\"]), main=\"Histogram of urinary incontinence scores at month 1\", xlab=\"Score\")\n\n\n\n\n\n\nThe median and interquartile range among the 1,405 participants with sufficient responses to calculate the domain score is\n\nCodequantile(w[\"Uscore.3\"], c(.25, .5, .75), na.rm=T)\n\n25% 50% 75% \n 46  60  77 \n\n\nA histogram of the available scores shown below.\n\nCodehist(unlist(w[\"Uscore.3\"]), main=\"Histogram of urinary incontinence scores at month 3\", xlab=\"Score\")\n\n\n\n\n\n\nThe median and interquartile range among the 1,360 participants with sufficient responses to calculate the domain score is\n\nCodequantile(w[\"Uscore.6\"], c(.25, .5, .75), na.rm=T)\n\n25% 50% 75% \n 58  71  92 \n\n\nA histogram of the available scores shown below.\n\nCodehist(unlist(w[\"Uscore.6\"]), main=\"Histogram of urinary incontinence scores at month 6\", xlab=\"Score\")\n\n\n\n\n\n\nThe median and interquartile range among the 1,409 participants with sufficient responses to calculate the domain score is\n\nCodequantile(w[\"Uscore.12\"], c(.25, .5, .75), na.rm=T)\n\n25% 50% 75% \n 60  77 100 \n\n\nA histogram of the available scores shown below.\n\nCodehist(unlist(w[\"Uscore.12\"]), main=\"Histogram of urinary incontinence scores at month 12\", xlab=\"Score\")\n\n\n\n\n\n\n\n\n\n\n\nBaseline\nMonth 1\nMonth 3\nMonth 6\nMonth 12\n\n\n\nThe median and interquartile range among the 1,953 participants with sufficient responses to calculate the domain score is\n\nCodequantile(w[\"Sscore.0\"], c(.25, .5, .75), na.rm=T)\n\n25% 50% 75% \n 42  71  92 \n\n\nA histogram of the available scores shown below.\n\nCodehist(unlist(w[\"Sscore.0\"]), main=\"Histogram of sexual function scores at baseline\", xlab=\"Score\")\n\n\n\n\n\n\nThe median and interquartile range among the 1,368 participants with sufficient responses to calculate the domain score is\n\nCodequantile(w[\"Sscore.1\"], c(.25, .5, .75), na.rm=T)\n\n 25%  50%  75% \n 4.2 12.5 18.0 \n\n\nA histogram of the available scores shown below.\n\nCodehist(unlist(w[\"Sscore.1\"]), main=\"Histogram of sexual function scores at month 1\", xlab=\"Score\")\n\n\n\n\n\n\nThe median and interquartile range among the 1,343 participants with sufficient responses to calculate the domain score is\n\nCodequantile(w[\"Sscore.3\"], c(.25, .5, .75), na.rm=T)\n\n 25%  50%  75% \n 4.2 13.8 25.0 \n\n\nA histogram of the available scores shown below.\n\nCodehist(unlist(w[\"Sscore.3\"]), main=\"Histogram of sexual function scores at month 3\", xlab=\"Score\")\n\n\n\n\n\n\nThe median and interquartile range among the 1,321 participants with sufficient responses to calculate the domain score is\n\nCodequantile(w[\"Sscore.6\"], c(.25, .5, .75), na.rm=T)\n\n 25%  50%  75% \n 8.3 16.7 30.5 \n\n\nA histogram of the available scores shown below.\n\nCodehist(unlist(w[\"Sscore.6\"]), main=\"Histogram of sexual function scores at month 6\", xlab=\"Score\")\n\n\n\n\n\n\nThe median and interquartile range among the 1,350 participants with sufficient responses to calculate the domain score is\n\nCodequantile(w[\"Sscore.12\"], c(.25, .5, .75), na.rm=T)\n\n 25%  50%  75% \n 8.3 18.0 40.3 \n\n\nA histogram of the available scores shown below.\n\nCodehist(unlist(w[\"Sscore.12\"]), main=\"Histogram of sexual function scores at month 12\", xlab=\"Score\")\n\n\n\n\n\n\n\n\n\n\nBaseline complete case results\nHere, reported frequencies of reported PROMs at baseline are presented. These results are used in the main body of the text. Complete case analysis using only participants with baseline data available is used so that the proportions can easily be compared.\nFrequencies of the reported outcomes are shown in tables. Proportions of participants are then given with 95% confidence intervals constructed using Wilson’s method.\n\n\nUrinary\nSexual\n\n\n\nParticipants with complete urinary continence domain question data at baseline.\n\n\nLeakage\nPad use\nLeakage and pad use\nUrinary score\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine?\n\nCodebar_tab(ub$A23.0, \"Leakage\", \"Count\")\n\n\n\n\nProportion rarely or never leaking urine.\n\nCodeprop_conf(ub$A23.0, \"Rarely or never\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.77\n0.75\n0.79\n\n\n\n\n\nProportion with leakage\n\nCodeprop_conf(ub$A23.0, \"Rarely or never\", T)\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.23\n0.21\n0.25\n\n\n\n\n\n\n\nQ27: How many pads per day did you usually use to control leakage during the last 4 weeks?\n\nCodebar_tab(ub$A27.0, \"Pad use\", \"Count\")\n\n\n\n\nProportion using no pads per day.\n\nCodeprop_conf(ub$A27.0, \"None\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.97\n0.96\n0.97\n\n\n\n\n\nProportion using pads\n\nCodeprop_conf(ub$A27.0, \"None\", T)\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.034\n0.027\n0.043\n\n\n\n\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine? AND Q27: How many pads per day did you usually use to control leakage during the last 4 weeks?\n\nCodebar_tab2(ub$A23.0, ub$A27.0, \"Leakage\", \"Count\", \"Pad use\", missing=F)\n\n\n\n\nProportion who were leak free and pad free at baseline.\n\nCodeprop_conf2(ub$A23.0, ub$A27.0, \"Rarely or never\", \"None\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.77\n0.75\n0.78\n\n\n\n\n\n\n\nThe median and interquartile range was\n\nCodequantile(ub[\"Uscore.0\"], c(.25, .5, .75), na.rm=T)\n\n25% 50% 75% \n 86 100 100 \n\n\n\n\n\n\n\nParticipants with complete sexual function domain question data at baseline.\n\n\nQuality\nAssistance\nSexual function score\n\n\n\nQ59: How would you describe the usual QUALITY of your erections during the last 4 weeks? AND Have you used any medications or devices to aid or improve erections?\n\nCodebar_tab2(sb$A59.0, sb$Assist.0, \"Quality\", \"Count\", \"Medication and device Use\", F, save=\"Figures/Figure3C.jpg\")\n\n\n\n\nProportion with natural erections firm enough for intercourse.\n\nCodeprop_conf2(sb$A59.0, sb$Assist.0, \"Firm enough for intercourse\", \"No\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.52\n0.5\n0.54\n\n\n\n\n\n\n\nThere are missing values here as use of medications and devices is not included as a question in the sexual function domain.\n\nCodeassist_use(sb, 0)\n\n\n\n\n\n\nThe median and interquartile range was\n\nCodequantile(sb[\"Sscore.0\"], c(.25, .5, .75), na.rm=T)\n\n25% 50% 75% \n 43  74  92 \n\n\n\n\n\n\n\n\nTwelve month results\nHere, reported frequencies of reported PROMs at 12 months are presented. These results are used in the main body of the text. Complete case analysis using only participants with baseline and 12 month data available is used so that the proportions can easily be compared.\nFrequencies of the reported outcomes are shown in tables. Proportions of participants are then given with 95% confidence intervals constructed using Wilson’s method.\n\n\nUrinary\nSexual\n\n\n\n\n\nAll\nBaseline leak-free\nBaseline pad-free\nBaseline leak-free and pad-free\nNot baseline leak-free and pad-free\n\n\n\n\n\nLeakage\nPad use\nLeakage and pad use\nScore\nSpaghetti Plot\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine?\n\nCodebar_tab(uf$A23.12, \"Leakage\", \"Count\")\n\n\n\n\nLeak free proportion\n\nCodeprop_conf(uf$A23.12, \"Rarely or never\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.45\n0.42\n0.47\n\n\n\n\n\n\n\nQ27: How many pads per day did you usually use to control leakage during the last 4 weeks?\n\nCodebar_tab(uf$A27.12, \"Pad use\", \"Count\")\n\n\n\n\nPad free proportion\n\nCodeprop_conf(uf$A27.12, \"None\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.65\n0.63\n0.68\n\n\n\n\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine? AND Q27: How many pads per day did you usually use to control leakage during the last 4 weeks?\n\nCodebar_tab2(uf$A23.12, uf$A27.12, \"Leakage\", \"Count\", \"Pad use\", missing=F)\n\n\n\n\nProportion pad free and leak free\n\nCodeprop_conf2(uf$A23.12, uf$A27.12, \"Rarely or never\", \"None\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.42\n0.39\n0.45\n\n\n\n\n\n\n\nMedian and interquartile range of the urinary function score\n\nCodequantile(uf$Uscore.12, c(.25, .5, .75), na.rm=T)\n\n25% 50% 75% \n 60  76 100 \n\n\n\n\nHere is the spaghetti plot for all participants at all time points.\n\nCodespaghetti(l, l$Time, l$Uscore, l$Study_ID)\n\n\n\n\n\n\n\n\n\n\n\nLeakage\nPad use\nLeakage and pad use\nScore\nSpaghetti Plot\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine?\n\nCodebar_tab(temp$A23.12, \"Leakage\", \"Count\")\n\n\n\n\nLeak free proportion\n\nCodeprop_conf(temp$A23.12, \"Rarely or never\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.5\n0.47\n0.53\n\n\n\n\n\n\n\nQ27: How many pads per day did you usually use to control leakage during the last 4 weeks?\n\nCodebar_tab(temp$A27.12, \"Pad use\", \"Count\")\n\n\n\n\nPad free proportion\n\nCodeprop_conf(temp$A27.12, \"None\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.7\n0.67\n0.72\n\n\n\n\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine? AND Q27: How many pads per day did you usually use to control leakage during the last 4 weeks?\n\nCodebar_tab2(temp$A23.12, temp$A27.12, \"Leakage\", \"Count\", \"Pad use\", missing=F)\n\n\n\n\nProportion pad free and leak free\n\nCodeprop_conf2(temp$A23.12, temp$A27.12, \"Rarely or never\", \"None\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.48\n0.45\n0.51\n\n\n\n\n\n\n\nMedian and interquartile range of the urinary function score\n\nCodequantile(temp$Uscore.12, c(.25, .5, .75), na.rm=T)\n\n25% 50% 75% \n 65  84 100 \n\n\n\n\nHere is the spaghetti plot for all participants at all time points.\n\nCoded_tmp = l[l$Study_ID %in% temp$Study_ID,]\nspaghetti(d_tmp, d_tmp$Time, d_tmp$Uscore, d_tmp$Study_ID)\n\n\n\n\n\n\n\n\n\n\n\nLeakage\nPad use\nLeakage and pad use\nScore\nSpaghetti Plot\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine?\n\nCodebar_tab(temp$A23.12, \"Leakage\", \"Count\")\n\n\n\n\nLeak free proportion\n\nCodeprop_conf(temp$A23.12, \"Rarely or never\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.45\n0.43\n0.48\n\n\n\n\n\n\n\nQ27: How many pads per day did you usually use to control leakage during the last 4 weeks?\n\nCodebar_tab(temp$A27.12, \"Pad use\", \"Count\")\n\n\n\n\nPad free proportion\n\nCodeprop_conf(temp$A27.12, \"None\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.66\n0.64\n0.69\n\n\n\n\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine? AND Q27: How many pads per day did you usually use to control leakage during the last 4 weeks?\n\nCodebar_tab2(temp$A23.12, temp$A27.12, \"Leakage\", \"Count\", \"Pad use\", missing=F)\n\n\n\n\nProportion pad free and leak free\n\nCodeprop_conf2(temp$A23.12, temp$A27.12, \"Rarely or never\", \"None\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.43\n0.4\n0.45\n\n\n\n\n\n\n\nMedian and interquartile range of the urinary function score\n\nCodequantile(temp$Uscore.12, c(.25, .5, .75), na.rm=T)\n\n25% 50% 75% \n 60  77 100 \n\n\n\n\nHere is the spaghetti plot for all participants at all time points.\n\nCoded_tmp = l[l$Study_ID %in% temp$Study_ID,]\nspaghetti(d_tmp, d_tmp$Time, d_tmp$Uscore, d_tmp$Study_ID)\n\n\n\n\n\n\n\n\n\n\n\nLeakage\nPad use\nLeakage and pad use\nScore\nSpaghetti Plot\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine?\n\nCodebar_tab(temp$A23.12, \"Leakage\", \"Count\")\n\n\n\n\nLeak free proportion\n\nCodeprop_conf(temp$A23.12, \"Rarely or never\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.51\n0.48\n0.54\n\n\n\n\n\n\n\nQ27: How many pads per day did you usually use to control leakage during the last 4 weeks?\n\nCodebar_tab(temp$A27.12, \"Pad use\", \"Count\")\n\n\n\n\nPad free proportion\n\nCodeprop_conf(temp$A27.12, \"None\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.7\n0.67\n0.72\n\n\n\n\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine? AND Q27: How many pads per day did you usually use to control leakage during the last 4 weeks?\n\nCodebar_tab2(temp$A23.12, temp$A27.12, \"Leakage\", \"Count\", \"Pad use\", missing=F)\n\n\n\n\nProportion pad free and leak free\n\nCodeprop_conf2(temp$A23.12, temp$A27.12, \"Rarely or never\", \"None\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.48\n0.45\n0.51\n\n\n\n\n\n\n\nMedian and interquartile range of the urinary function score\n\nCodequantile(temp$Uscore.12, c(.25, .5, .75), na.rm=T)\n\n25% 50% 75% \n 65  84 100 \n\n\n\n\nHere is the spaghetti plot for all participants at all time points.\n\nCoded_tmp = l[l$Study_ID %in% temp$Study_ID,]\nspaghetti(d_tmp, d_tmp$Time, d_tmp$Uscore, group=d_tmp$Study_ID)\n\n\n\n\n\n\n\n\n\n\n\nLeakage\nPad use\nLeakage and pad use\nScore\nSpaghetti Plot\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine?\n\nCodebar_tab(temp$A23.12, \"Leakage\", \"Count\")\n\n\n\n\nLeak free proportion\n\nCodeprop_conf(temp$A23.12, \"Rarely or never\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.23\n0.19\n0.28\n\n\n\n\n\n\n\nQ27: How many pads per day did you usually use to control leakage during the last 4 weeks?\n\nCodebar_tab(temp$A27.12, \"Pad use\", \"Count\")\n\n\n\n\nPad free proportion\n\nCodeprop_conf(temp$A27.12, \"None\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.48\n0.43\n0.54\n\n\n\n\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine? AND Q27: How many pads per day did you usually use to control leakage during the last 4 weeks?\n\nCodebar_tab2(temp$A23.12, temp$A27.12, \"Leakage\", \"Count\", \"Pad use\", missing=F)\n\n\n\n\nProportion pad free and leak free\n\nCodeprop_conf2(temp$A23.12, temp$A27.12, \"Rarely or never\", \"None\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.2\n0.16\n0.25\n\n\n\n\n\n\n\nMedian and interquartile range of the urinary function score\n\nCodequantile(temp$Uscore.12, c(.25, .5, .75), na.rm=T)\n\n25% 50% 75% \n 52  65  79 \n\n\n\n\nHere is the spaghetti plot for all participants at all time points.\n\nCoded_tmp = l[l$Study_ID %in% temp$Study_ID,]\nspaghetti(d_tmp, d_tmp$Time, d_tmp$Uscore, d_tmp$Study_ID)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAll participants\nNatural at baseline\nNot natural erections at baseline\n\n\n\n\n\nErection quality\nAssistance use\nScore\nPlot\n\n\n\nQ59: How would you describe the usual QUALITY of your erections during the last 4 weeks? AND Have you used any medications or devices to aid or improve erections?\n\nCodebar_tab2(sf$A59.12, sf$Assist.12, \"Quality\", \"Count\", \"Medication and device use\", missing=F, save=\"Figures/Figure3D.jpg\")\n\n\n\n\nProportion with adequate erections\n\nCodeprop_conf(sf$A59.12, \"Firm enough for intercourse\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.1\n0.088\n0.12\n\n\n\n\n\nProportion with natural adequate erections\n\nCodeprop_conf2(sf$A59.12, sf$Assist.12, \"Firm enough for intercourse\", \"No\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.035\n0.026\n0.047\n\n\n\n\n\nProportion with assisted adequate erections\n\nCodeprop_conf2(sf$A59.12, sf$Assist.12, \"Firm enough for intercourse\", \"Yes\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.069\n0.056\n0.085\n\n\n\n\n\nProportion without adequate erections\n\nCodeprop_conf(sf$A59.12, \"Firm enough for intercourse\", T)\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.9\n0.88\n0.91\n\n\n\n\n\n\n\n\nCodeassist_use(sf, 12)\n\n\n\n\n\n\nThe median score and interquartile range was\n\nCodequantile(sf$Sscore.12, c(.25, .5, .75), na.rm=T)\n\n 25%  50%  75% \n 8.3 18.0 40.3 \n\n\n\n\nA spaghetti plot of the sexual function scores is shown below\n\nCodespaghetti(l, l$Time, l$Sscore, l$Study_ID)\n\n\n\n\n\n\n\n\n\n\n\nErection quality\nAssistance use\nScore\nPlot\n\n\n\nQ59: How would you describe the usual QUALITY of your erections during the last 4 weeks? AND Have you used any medications or devices to aid or improve erections?\n\nCodebar_tab2(temp$A59.12, temp$Assist.12, \"Erection\", \"Count\", \"Medication and device use\", missing=F)\n\n\n\n\nProportion with adequate erections\n\nCodeprop_conf(temp$A59.12, \"Firm enough for intercourse\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.17\n0.14\n0.2\n\n\n\n\n\nProportion with natural adequate erections\n\nCodeprop_conf2(temp$A59.12, temp$Assist.12, \"Firm enough for intercourse\", \"No\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.059\n0.043\n0.08\n\n\n\n\n\nProportion with assisted adequate erections\n\nCodeprop_conf2(temp$A59.12, temp$Assist.12, \"Firm enough for intercourse\", \"Yes\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.11\n0.086\n0.13\n\n\n\n\n\nProportion without adequate erections\n\nCodeprop_conf(temp$A59.12, \"Firm enough for intercourse\", T)\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.83\n0.8\n0.86\n\n\n\n\n\n\n\n\nCodeassist_use(temp, 12)\n\n\n\n\n\n\nThe median score and interquartile range was\n\nCodequantile(temp$Sscore.12, c(.25, .5, .75), na.rm=T)\n\n25% 50% 75% \n 12  26  57 \n\n\n\n\nA spaghetti plot of the sexual function scores is shown below\n\nCoded_tmp = l[l$Study_ID %in% temp$Study_ID,]\nspaghetti(d_tmp, d_tmp$Time, d_tmp$Sscore, d_tmp$Study_ID)\n\n\n\n\n\n\n\n\n\n\n\nErection quality\nAssistance use\nScore\nPlot\n\n\n\nQ59: How would you describe the usual QUALITY of your erections during the last 4 weeks? AND Have you used any medications or devices to aid or improve erections?\n\nCodebar_tab2(temp$A59.12, temp$Assist.12, \"Quality\", \"Count\", \"Medication and device use\", missing=F)\n\n\n\n\nProportion with adequate erections\n\nCodeprop_conf(temp$A59.12, \"Firm enough for intercourse\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.035\n0.023\n0.054\n\n\n\n\n\nProportion with natural adequate erections\n\nCodeprop_conf2(temp$A59.12, temp$Assist.12, \"Firm enough for intercourse\", \"No\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.0088\n0.0038\n0.02\n\n\n\n\n\nProportion with assisted adequate erections\n\nCodeprop_conf2(temp$A59.12, temp$Assist.12, \"Firm enough for intercourse\", \"Yes\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.026\n0.016\n0.043\n\n\n\n\n\nProportion without adequate erections\n\nCodeprop_conf(temp$A59.12, \"Firm enough for intercourse\", T)\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.96\n0.95\n0.98\n\n\n\n\n\n\n\n\nCodeassist_use(temp, 12)\n\n\n\n\n\n\nThe median score and interquartile range was\n\nCodequantile(temp$Sscore.12, c(.25, .5, .75), na.rm=T)\n\n 25%  50%  75% \n 8.3 16.7 27.8 \n\n\n\n\nA spaghetti plot of the sexual function scores is shown below\n\nCoded_tmp = l[l$Study_ID %in% temp$Study_ID,]\nspaghetti(d_tmp, d_tmp$Time, d_tmp$Sscore, d_tmp$Study_ID)\n\n\n\n\n\n\n\n\n\n\n\n\n\nScore and definitions comparison\n\n\nContinence recovery\nSexual function recovery\n\n\n\n\n\nAll\nBaseline leak-free\nBaseline pad-free\nBaseline leak and pad-free\n\n\n\n\n\nLeak free\nPad free\nLeak and pad free\nScore\n\n\n\nTable of the proportion leak free at each time point with upper and lower 95% confidence intervals.\n\nCodetimes_leakfree(all_tmp)\n\n\n\n\n\n\nTime\nFrequency\nPoint\nLower\nUpper\n\n\n\n0\n691\n0.78\n0.755\n0.81\n\n\n1\n92\n0.10\n0.086\n0.13\n\n\n3\n190\n0.22\n0.190\n0.24\n\n\n6\n337\n0.38\n0.351\n0.41\n\n\n12\n411\n0.47\n0.433\n0.50\n\n\n\n\n\n\n\n\nTable of the proportion pad free at each time point with upper and lower 95% confidence intervals.\n\nCodetimes_padfree(all_tmp)\n\n\n\n\n\n\nTime\nFrequency\nPoint\nLower\nUpper\n\n\n\n0\n862\n0.98\n0.965\n0.99\n\n\n1\n101\n0.11\n0.095\n0.14\n\n\n3\n266\n0.30\n0.272\n0.33\n\n\n6\n465\n0.53\n0.494\n0.56\n\n\n12\n571\n0.65\n0.615\n0.68\n\n\n\n\n\n\n\n\nTable of the proportion leak and pad free at each time point with upper and lower 95% confidence intervals.\n\nCodetimes_leakpadfree(all_tmp)\n\n\n\n\n\n\nTime\nFrequency\nPoint\nLower\nUpper\n\n\n\n0\n687\n0.779\n0.750\n0.805\n\n\n1\n64\n0.073\n0.057\n0.092\n\n\n3\n165\n0.187\n0.163\n0.214\n\n\n6\n302\n0.342\n0.312\n0.374\n\n\n12\n385\n0.437\n0.404\n0.469\n\n\n\n\n\n\n\n\nA table showing the median and interquartile range at the different time points is given below\n\nCodetimes_Uscore(all_tmp)\n\n\n\n\n\n\nTime\nMedian\nLower.IQR\nUpper.IQR\n\n\n\nBaseline\n100\n86\n100\n\n\nMonth 1\n50\n27\n65\n\n\nMonth 3\n60\n48\n77\n\n\nMonth 6\n71\n58\n94\n\n\nMonth 12\n77\n60\n100\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeak free\nPad free\nLeak and pad free\nScore\n\n\n\nTable of the proportion leak free at each time point with upper and lower 95% confidence intervals.\n\nCodetimes_leakfree(all_tmp)\n\n\n\n\n\n\nTime\nFrequency\nPoint\nLower\nUpper\n\n\n\n0\n691\n1.00\n0.994\n1.00\n\n\n1\n82\n0.12\n0.097\n0.14\n\n\n3\n167\n0.24\n0.211\n0.27\n\n\n6\n290\n0.42\n0.383\n0.46\n\n\n12\n364\n0.53\n0.490\n0.56\n\n\n\n\n\n\n\n\nTable of the proportion pad free at each time point with upper and lower 95% confidence intervals.\n\nCodetimes_padfree(all_tmp)\n\n\n\n\n\n\nTime\nFrequency\nPoint\nLower\nUpper\n\n\n\n0\n687\n0.99\n0.99\n1.00\n\n\n1\n87\n0.13\n0.10\n0.15\n\n\n3\n214\n0.31\n0.28\n0.35\n\n\n6\n391\n0.57\n0.53\n0.60\n\n\n12\n476\n0.69\n0.65\n0.72\n\n\n\n\n\n\n\n\nTable of the proportion leak and pad free at each time point with upper and lower 95% confidence intervals.\n\nCodetimes_leakpadfree(all_tmp)\n\n\n\n\n\n\nTime\nFrequency\nPoint\nLower\nUpper\n\n\n\n0\n687\n0.994\n0.985\n1.00\n\n\n1\n60\n0.087\n0.068\n0.11\n\n\n3\n143\n0.207\n0.178\n0.24\n\n\n6\n260\n0.376\n0.341\n0.41\n\n\n12\n345\n0.499\n0.462\n0.54\n\n\n\n\n\n\n\n\nA table showing the median and interquartile range at the different time points is given below\n\nCodetimes_Uscore(all_tmp)\n\n\n\n\n\n\nTime\nMedian\nLower.IQR\nUpper.IQR\n\n\n\nBaseline\n100\n100\n100\n\n\nMonth 1\n50\n29\n65\n\n\nMonth 3\n65\n50\n79\n\n\nMonth 6\n73\n60\n94\n\n\nMonth 12\n86\n65\n100\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeak free\nPad free\nLeak and pad free\nScore\n\n\n\nTable of the proportion leak free at each time point with upper and lower 95% confidence intervals.\n\nCodetimes_leakfree(all_tmp)\n\n\n\n\n\n\nTime\nFrequency\nPoint\nLower\nUpper\n\n\n\n0\n687\n0.80\n0.769\n0.82\n\n\n1\n92\n0.11\n0.088\n0.13\n\n\n3\n189\n0.22\n0.193\n0.25\n\n\n6\n335\n0.39\n0.357\n0.42\n\n\n12\n408\n0.47\n0.440\n0.51\n\n\n\n\n\n\n\n\nTable of the proportion pad free at each time point with upper and lower 95% confidence intervals.\n\nCodetimes_padfree(all_tmp)\n\n\n\n\n\n\nTime\nFrequency\nPoint\nLower\nUpper\n\n\n\n0\n862\n1.00\n0.996\n1.00\n\n\n1\n101\n0.12\n0.097\n0.14\n\n\n3\n264\n0.31\n0.276\n0.34\n\n\n6\n463\n0.54\n0.504\n0.57\n\n\n12\n568\n0.66\n0.627\n0.69\n\n\n\n\n\n\n\n\nTable of the proportion leak and pad free at each time point with upper and lower 95% confidence intervals.\n\nCodetimes_leakpadfree(all_tmp)\n\n\n\n\n\n\nTime\nFrequency\nPoint\nLower\nUpper\n\n\n\n0\n687\n0.797\n0.769\n0.822\n\n\n1\n64\n0.074\n0.059\n0.094\n\n\n3\n164\n0.190\n0.165\n0.218\n\n\n6\n301\n0.349\n0.318\n0.382\n\n\n12\n383\n0.444\n0.411\n0.478\n\n\n\n\n\n\n\n\nA table showing the median and interquartile range at the different time points is given below\n\nCodetimes_Uscore(all_tmp)\n\n\n\n\n\n\nTime\nMedian\nLower.IQR\nUpper.IQR\n\n\n\nBaseline\n100\n86\n100\n\n\nMonth 1\n50\n27\n65\n\n\nMonth 3\n62\n50\n77\n\n\nMonth 6\n71\n58\n94\n\n\nMonth 12\n77\n60\n100\n\n\n\n\n\n\n\n\n\n\n\n\n\nLeak free\nPad free\nLeak and pad free\nScore\n\n\n\nTable of the proportion leak free at each time point with upper and lower 95% confidence intervals.\n\nCodetimes_leakfree(all_tmp)\n\n\n\n\n\n\nTime\nFrequency\nPoint\nLower\nUpper\n\n\n\n0\n687\n1.00\n0.994\n1.00\n\n\n1\n82\n0.12\n0.097\n0.15\n\n\n3\n167\n0.24\n0.212\n0.28\n\n\n6\n290\n0.42\n0.386\n0.46\n\n\n12\n364\n0.53\n0.492\n0.57\n\n\n\n\n\n\n\n\nTable of the proportion pad free at each time point with upper and lower 95% confidence intervals.\n\nCodetimes_padfree(all_tmp)\n\n\n\n\n\n\nTime\nFrequency\nPoint\nLower\nUpper\n\n\n\n0\n687\n1.00\n0.99\n1.00\n\n\n1\n87\n0.13\n0.10\n0.15\n\n\n3\n214\n0.31\n0.28\n0.35\n\n\n6\n391\n0.57\n0.53\n0.61\n\n\n12\n476\n0.69\n0.66\n0.73\n\n\n\n\n\n\n\n\nTable of the proportion leak and pad free at each time point with upper and lower 95% confidence intervals.\n\nCodetimes_leakpadfree(all_tmp)\n\n\n\n\n\n\nTime\nFrequency\nPoint\nLower\nUpper\n\n\n\n0\n687\n1.000\n0.994\n1.00\n\n\n1\n60\n0.087\n0.068\n0.11\n\n\n3\n143\n0.208\n0.179\n0.24\n\n\n6\n260\n0.378\n0.343\n0.42\n\n\n12\n345\n0.502\n0.465\n0.54\n\n\n\n\n\n\n\n\nA table showing the median and interquartile range at the different time points is given below\n\nCodetimes_Uscore(all_tmp)\n\n\n\n\n\n\nTime\nMedian\nLower.IQR\nUpper.IQR\n\n\n\nBaseline\n100\n100\n100\n\n\nMonth 1\n50\n29\n65\n\n\nMonth 3\n65\n50\n79\n\n\nMonth 6\n73\n60\n94\n\n\nMonth 12\n86\n65\n100\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAll\nNatural at baseline\n\n\n\n\n\nNatural erections\nAssisted\nMedian\n\n\n\nTable of the proportion of adequate natural erections at each time point with upper and lower 95% confidence intervals.\n\nCodetimes_natural(all_tmp)\n\n\n\n\n\n\nTime\nFrequency\nPoint\nLower\nUpper\n\n\n\n0\n344\n0.501\n0.463\n0.538\n\n\n1\n17\n0.025\n0.016\n0.039\n\n\n3\n13\n0.019\n0.011\n0.032\n\n\n6\n17\n0.025\n0.016\n0.039\n\n\n12\n24\n0.035\n0.024\n0.051\n\n\n\n\n\n\n\n\nTable of the proportion of adequate assisted erections at each time point with upper and lower 95% confidence intervals.\n\nCodetimes_assist(all_tmp)\n\n\n\n\n\n\nTime\nFrequency\nPoint\nLower\nUpper\n\n\n\n0\n42\n0.0611\n0.045545\n0.0816\n\n\n1\n1\n0.0015\n0.000075\n0.0082\n\n\n3\n10\n0.0146\n0.007925\n0.0266\n\n\n6\n18\n0.0262\n0.016636\n0.0410\n\n\n12\n38\n0.0553\n0.040561\n0.0750\n\n\n\n\n\n\n\n\nA table showing the median and interquartile range at the different time points is given below\n\nCodetimes_Sscore(all_tmp)\n\n\n\n\n\n\nTime\nMedian\nLower.IQR\nUpper.IQR\n\n\n\nBaseline\n75\n44.5\n92\n\n\nMonth 1\n14\n4.2\n20\n\n\nMonth 3\n17\n5.5\n26\n\n\nMonth 6\n17\n8.3\n32\n\n\nMonth 12\n20\n12.5\n42\n\n\n\n\n\n\n\n\n\n\n\n\n\nNatural erections\nAssisted\nMedian\n\n\n\nTable of the proportion of adequate natural erections at each time point with upper and lower 95% confidence intervals.\n\nCodetimes_natural(all_tmp)\n\n\n\n\n\n\nTime\nFrequency\nPoint\nLower\nUpper\n\n\n\n0\n344\n1.000\n0.989\n1.000\n\n\n1\n16\n0.047\n0.029\n0.074\n\n\n3\n13\n0.038\n0.022\n0.064\n\n\n6\n16\n0.047\n0.029\n0.074\n\n\n12\n22\n0.064\n0.043\n0.095\n\n\n\n\n\n\n\n\nTable of the proportion of adequate assisted erections at each time point with upper and lower 95% confidence intervals.\n\nCodetimes_assist(all_tmp)\n\n\n\n\n\n\nTime\nFrequency\nPoint\nLower\nUpper\n\n\n\n0\n0\n0.0000\n0.00000\n0.011\n\n\n1\n1\n0.0029\n0.00015\n0.016\n\n\n3\n10\n0.0291\n0.01587\n0.053\n\n\n6\n14\n0.0407\n0.02440\n0.067\n\n\n12\n28\n0.0814\n0.05691\n0.115\n\n\n\n\n\n\n\n\nA table showing the median and interquartile range at the different time points is given below\n\nCodetimes_Sscore(all_tmp)\n\n\n\n\n\n\nTime\nMedian\nLower.IQR\nUpper.IQR\n\n\n\nBaseline\n91\n83.3\n100\n\n\nMonth 1\n17\n4.2\n26\n\n\nMonth 3\n17\n8.3\n36\n\n\nMonth 6\n18\n8.3\n40\n\n\nMonth 12\n28\n12.5\n56\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAll time points\n\n\nLeakage\nPad use\nErection quality\n\n\n\nLeakage at all time points for 915 participants who reported leakage at every time point.\nQ23: Over the last 4 weeks, how often have you leaked urine?\n\nCodetl = w[!is.na(w$A23.0) & !is.na(w$A23.1) & !is.na(w$A23.3) & !is.na(w$A23.6) & !is.na(w$A23.12),] \ntl = l[l$Study_ID %in% tl$Study_ID,]\nbar_tab2(tl$Time, tl$A23,\"Time\", \"Count\", \"Leakage\", missing=F)\n\n\n\n\n\n\nLeakage at all time points for 939 participants who reported leakage at every time point.\nQ27: Over the last 4 weeks, how often have you leaked urine?\n\nCodetl = w[!is.na(w$A27.0) & !is.na(w$A27.1) & !is.na(w$A27.3) & !is.na(w$A27.6) & !is.na(w$A27.12),] \ntl = l[l$Study_ID %in% tl$Study_ID,]\nbar_tab2(tl$Time, tl$A27,\"Time\", \"Count\", \"Pad use\", missing=F)\n\n\n\n\n\n\nErection quality at all time points for 822 participants who reported erection quality at every time point.\nQ59: How would you rate the usual QUALITY if your erections during the last 4 weeks?\n\nCodetl = w[!is.na(w$A59.0) & !is.na(w$A59.1) & !is.na(w$A59.3) & !is.na(w$A59.6) & !is.na(w$A59.12),] \ntl = l[l$Study_ID %in% tl$Study_ID,]\nbar_tab2(tl$Time, tl$A59,\"Time\", \"Count\", \"Erection quality\", missing=F)\n\n\n\n\n\n\n\nProblem scores\n\n\nLeaking problem\nOverall urinary problem\nSexual function problem\n\n\n\nQ28: How big a problem, if any, has each of the following been for you during the last 4 weeks? Dripping or leaking urine\n\nCodeLpcp(lp)\n\n\n\n\n\n\nAll\nNo problem at baseline\n\n\n\nTwelve month results for leakage.\n\nCodetab = proc_freq(lp, \"A28.12\")\ntab = set_header_labels(tab, A28.12=\"Problem\", count=\"Number of participants\")\ntab\n\n\n\n\n\n\nProblem\nNumber of participants\nPercent\n\n\n\nNo Problem\n543\n38.1%\n\n\nVery Small Problem\n554\n38.9%\n\n\nSmall Problem\n197\n13.8%\n\n\nModerate Problem\n78\n5.5%\n\n\nBig Problem\n52\n3.7%\n\n\nTotal\n1,424\n100.0%\n\n\n\n\n\n\nProportion with no problems\n\nCodeprop_conf(lp$A28.12, \"No Problem\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.38\n0.36\n0.41\n\n\n\n\n\nProportion with small problem or lower\n\nCodeprop_conf(lp$A28.12, c(\"No Problem\", \"Very Small Problem\", \"Small Problem\"))\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.91\n0.89\n0.92\n\n\n\n\n\n\n\nTwelve month results for leakage.\n\nCodel0 = lp[lp$A28.0==\"No Problem\",]\ntab = proc_freq(l0, \"A28.12\")\ntab = set_header_labels(tab, A28.12=\"Problem\", count=\"Number of participants\")\ntab\n\n\n\n\n\n\nProblem\nNumber of participants\nPercent\n\n\n\nNo Problem\n462\n44.8%\n\n\nVery Small Problem\n389\n37.7%\n\n\nSmall Problem\n109\n10.6%\n\n\nModerate Problem\n42\n4.1%\n\n\nBig Problem\n30\n2.9%\n\n\nTotal\n1,032\n100.0%\n\n\n\n\n\n\nProportion with no problems\n\nCodeprop_conf(l0$A28.12, \"No Problem\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.45\n0.42\n0.48\n\n\n\n\n\nProportion with small problem or lower\n\nCodeprop_conf(l0$A28.12, c(\"No Problem\", \"Very Small Problem\", \"Small Problem\"))\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.93\n0.91\n0.94\n\n\n\n\n\n\n\n\n\n\nQ34: Overall, how big a problem has your urinary function been for you during the last 4 weeks?\n\nCodeUpcp(up)\n\n\n\n\n\n\nAll\nNo problem at baseline\n\n\n\nTwelve month results for urinary function.\n\nCodetab = proc_freq(up, \"A34.12\")\ntab = set_header_labels(tab, A34.12=\"Problem\", count=\"Number of participants\")\ntab\n\n\n\n\n\n\nProblem\nNumber of participants\nPercent\n\n\n\nNo problem\n671\n47.0%\n\n\nVery small problem\n451\n31.6%\n\n\nSmall problem\n178\n12.5%\n\n\nModerate problem\n94\n6.6%\n\n\nBig problem\n34\n2.4%\n\n\nTotal\n1,428\n100.0%\n\n\n\n\n\n\nProportion with no problems\n\nCodeprop_conf(up$A34.12, \"No problem\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.47\n0.44\n0.5\n\n\n\n\n\nProportion with small problem or lower\n\nCodeprop_conf(up$A34.12, c(\"No problem\", \"Very small problem\", \"Small problem\"))\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.91\n0.89\n0.92\n\n\n\n\n\n\n\nTwelve month results for urinary function.\n\nCodeu0 = up[up$A34.0==\"No problem\",]\ntab = proc_freq(u0, \"A34.12\")\ntab = set_header_labels(tab, A34.12=\"Problem\", count=\"Number of participants\")\ntab\n\n\n\n\n\n\nProblem\nNumber of participants\nPercent\n\n\n\nNo problem\n400\n63.4%\n\n\nVery small problem\n169\n26.8%\n\n\nSmall problem\n38\n6.0%\n\n\nModerate problem\n17\n2.7%\n\n\nBig problem\n7\n1.1%\n\n\nTotal\n631\n100.0%\n\n\n\n\n\n\nProportion with no problems\n\nCodeprop_conf(u0$A34.12, \"No problem\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.63\n0.6\n0.67\n\n\n\n\n\nProportion with small problem or lower\n\nCodeprop_conf(up$A34.12, c(\"No problem\", \"Very small problem\", \"Small problem\"))\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.91\n0.89\n0.92\n\n\n\n\n\n\n\n\n\n\n\n\nAll\nNo problem at baseline\n\n\n\nTwelve month results for sexual function.\n\nCodetab = proc_freq(sp, \"A68.12\")\ntab = set_header_labels(tab, A68.12=\"Problem\", count=\"Number of participants\")\ntab\n\n\n\n\n\n\nProblem\nNumber of participants\nPercent\n\n\n\nNo problem\n248\n17.9%\n\n\nVery small problem\n233\n16.8%\n\n\nSmall problem\n302\n21.8%\n\n\nModerate problem\n321\n23.1%\n\n\nBig problem\n284\n20.5%\n\n\nTotal\n1,388\n100.0%\n\n\n\n\n\n\nProportion with no problems\n\nCodeprop_conf(sp$A68.12, \"No problem\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.18\n0.16\n0.2\n\n\n\n\n\nProportion with small problem or lower\n\nCodeprop_conf(sp$A68.12, c(\"No problem\", \"Very small problem\", \"Small problem\"))\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.56\n0.54\n0.59\n\n\n\n\n\n\n\nTwelve month results for sexual function.\n\nCodes0 = sp[sp$A68.0==\"No problem\",]\ntab = proc_freq(s0, \"A68.12\")\ntab = set_header_labels(tab, A68.12=\"Problem\", count=\"Number of participants\")\ntab\n\n\n\n\n\n\nProblem\nNumber of participants\nPercent\n\n\n\nNo problem\n180\n26.5%\n\n\nVery small problem\n125\n18.4%\n\n\nSmall problem\n137\n20.2%\n\n\nModerate problem\n131\n19.3%\n\n\nBig problem\n105\n15.5%\n\n\nTotal\n678\n100.0%\n\n\n\n\n\n\nProportion with no problems\n\nCodeprop_conf(sp$A68.12, \"No problem\")\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.18\n0.16\n0.2\n\n\n\n\n\nProportion with small problem or lower\n\nCodeprop_conf(sp$A68.12, c(\"No problem\", \"Very small problem\", \"Small problem\"))\n\n\n\n\n\n\nPointEst\nLower\nUpper\n\n\n0.56\n0.54\n0.59\n\n\n\n\n\n\n\n\n\n\n\nProblem and function\nThis sections shows problems associated with each of the function domains.\n\nCodetl = w[!is.na(w$A23.0) & !is.na(w$A23.1) & !is.na(w$A23.3) & !is.na(w$A23.6) & !is.na(w$A23.12) &\n  !is.na(w$A28.0) & !is.na(w$A28.1) & !is.na(w$A28.3) & !is.na(w$A28.6) & !is.na(w$A28.12),]\ntp = w[!is.na(w$A27.0) & !is.na(w$A27.1) & !is.na(w$A27.3) & !is.na(w$A27.6) & !is.na(w$A27.12) &\n  !is.na(w$A28.0) & !is.na(w$A28.1) & !is.na(w$A28.3) & !is.na(w$A28.6) & !is.na(w$A28.12),]\ntq = w[!is.na(w$A59.0) & !is.na(w$A59.1) & !is.na(w$A59.3) & !is.na(w$A59.6) & !is.na(w$A59.12) &\n  !is.na(w$A68.0) & !is.na(w$A68.1) & !is.na(w$A68.3) & !is.na(w$A68.6) & !is.na(w$A68.12),]\ntf = w[!is.na(w$A60.0) & !is.na(w$A60.1) & !is.na(w$A60.3) & !is.na(w$A60.6) & !is.na(w$A60.12) &\n  !is.na(w$A68.0) & !is.na(w$A68.1) & !is.na(w$A68.3) & !is.na(w$A68.6) & !is.na(w$A68.12),]\n\n\n\n\nLeakage\nPad use\nErection quality\nErection frequency\n\n\n\nComparison of the number of pads used and the leakage problem scor for those reporting leakage and leakage problem at all time points.\n\n\nBaseline\nMonth 1\nMonth 3\nMonth 6\nMonth 12\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine? AND Q28: How big a problem, if any, has each of the following been for you during the last 4 weeks? Dripping and leaking urine\n\nCodebar_tab2(tl$A23.0, tl$A28.0, \"Leakage\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine? AND Q28: How big a problem, if any, has each of the following been for you during the last 4 weeks? Dripping and leaking urine\n\nCodebar_tab2(tl$A23.1, tl$A28.1, \"Leakage\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine? AND Q28: How big a problem, if any, has each of the following been for you during the last 4 weeks? Dripping and leaking urine\n\nCodebar_tab2(tl$A23.3, tl$A28.3, \"Leakage\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine? AND Q28: How big a problem, if any, has each of the following been for you during the last 4 weeks? Dripping and leaking urine\n\nCodebar_tab2(tl$A23.6, tl$A28.6, \"Leakage\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\nQ23: Over the past four weeks, how often have you leaked urine? AND Q28: How big a problem, if any, has each of the following been for you during the last 4 weeks? Dripping and leaking urine\n\nCodebar_tab2(tl$A23.12, tl$A28.12, \"Leakage\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\n\n\n\nComparison of the number of pads used and the leakage problem score for those reporting pad-use and leakage problem at all time points.\n\n\nBaseline\nMonth 1\nMonth 3\nMonth 6\nMonth 12\n\n\n\nQ27: How many pads per day did you usually use to control leakage during the last 4 weeks? AND Q28: How big a problem, if any, has each of the following been for you during the last 4 weeks? Dripping and leaking urine\n\nCodebar_tab2(tp$A27.0, tp$A28.0, \"Pads\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\nQ27: How many pads per day did you usually use to control leakage during the last 4 weeks? AND Q28: How big a problem, if any, has each of the following been for you during the last 4 weeks? Dripping and leaking urine\n\nCodebar_tab2(tp$A27.1, tp$A28.1, \"Pads\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\nQ27: How many pads per day did you usually use to control leakage during the last 4 weeks? AND Q28: How big a problem, if any, has each of the following been for you during the last 4 weeks? Dripping and leaking urine\n\nCodebar_tab2(tp$A27.3, tp$A28.3, \"Pads\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\nQ27: How many pads per day did you usually use to control leakage during the last 4 weeks? AND Q28: How big a problem, if any, has each of the following been for you during the last 4 weeks? Dripping and leaking urine\n\nCodebar_tab2(tp$A27.6, tp$A28.6, \"Pads\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\nQ27: How many pads per day did you usually use to control leakage during the last 4 weeks? AND Q28: How big a problem, if any, has each of the following been for you during the last 4 weeks? Dripping and leaking urine\n\nCodebar_tab2(tp$A27.12, tp$A28.12, \"Pads\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\n\n\n\n\n\nBaseline\nMonth 1\nMonth 3\nMonth 6\nMonth 12\n\n\n\nQ59: How would you describe the usual QUALITY of your erections during the last 4 weeks? AND Q68: Overall, how big a problem has your sexual function or lack of sexual function been for you during the last 4 weeks?\n\nCodebar_tab2(tq$A59.0, tq$A68.0, \"Quality\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\nQ59: How would you describe the usual QUALITY of your erections during the last 4 weeks? AND Q68: Overall, how big a problem has your sexual function or lack of sexual function been for you during the last 4 weeks?\n\nCodebar_tab2(tq$A59.1, tq$A68.1, \"Quality\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\nQ59: How would you describe the usual QUALITY of your erections during the last 4 weeks? AND Q68: Overall, how big a problem has your sexual function or lack of sexual function been for you during the last 4 weeks?\n\nCodebar_tab2(tq$A59.3, tq$A68.3, \"Quality\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\nQ59: How would you describe the usual QUALITY of your erections during the last 4 weeks? AND Q68: Overall, how big a problem has your sexual function or lack of sexual function been for you during the last 4 weeks?\n\nCodebar_tab2(tq$A59.6, tq$A68.6, \"Quality\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\nQ59: How would you describe the usual QUALITY of your erections during the last 4 weeks? AND Q68: Overall, how big a problem has your sexual function or lack of sexual function been for you during the last 4 weeks?\n\nCodebar_tab2(tq$A59.12, tq$A68.12, \"Quality\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\n\n\n\nComparison of erection frequency and sexual function problem score for those reporting at every time point.\n\n\nBaseline\nMonth 1\nMonth 3\nMonth 6\nMonth 12\n\n\n\nQ60: How would you describe the FREQUENCY of your erections during the last 4 weeks? AND Q68: Overall, how big a problem has your sexual function or lack of sexual function been for you during the last 4 weeks?\n\nCodebar_tab2(tf$A60.0, tf$A68.0, \"Frequency\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\nQ60: How would you describe the FREQUENCY of your erections during the last 4 weeks? AND Q68: Overall, how big a problem has your sexual function or lack of sexual function been for you during the last 4 weeks?\n\nCodebar_tab2(tf$A60.1, tf$A68.1, \"Frequency\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\nQ60: How would you describe the FREQUENCY of your erections during the last 4 weeks? AND Q68: Overall, how big a problem has your sexual function or lack of sexual function been for you during the last 4 weeks?\n\nCodebar_tab2(tf$A60.3, tf$A68.3, \"Frequency\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\nQ60: How would you describe the FREQUENCY of your erections during the last 4 weeks? AND Q68: Overall, how big a problem has your sexual function or lack of sexual function been for you during the last 4 weeks?\n\nCodebar_tab2(tf$A60.6, tf$A68.6, \"Frequency\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\nQ60: How would you describe the FREQUENCY of your erections during the last 4 weeks? AND Q68: Overall, how big a problem has your sexual function or lack of sexual function been for you during the last 4 weeks?\n\nCodebar_tab2(tf$A60.12, tf$A68.12, \"Frequency\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\n\n\n\n\nProblem over time\n\nCodetl = w[!is.na(w$A28.0) & !is.na(w$A28.1) & !is.na(w$A28.3) & !is.na(w$A28.6) & !is.na(w$A28.12),]\ntu = w[!is.na(w$A34.0) & !is.na(w$A34.1) & !is.na(w$A34.3) & !is.na(w$A34.6) & !is.na(w$A34.12),]\nts = w[!is.na(w$A68.0) & !is.na(w$A68.1) & !is.na(w$A68.3) & !is.na(w$A68.6) & !is.na(w$A68.12),] \ntl = l[l$Study_ID %in% tl$Study_ID,]\ntu = l[l$Study_ID %in% tu$Study_ID,]\nts = l[l$Study_ID %in% ts$Study_ID,]\ntl = tl[!is.na(tl$A28),]\ntu = tu[!is.na(tu$A34),]\nts = ts[!is.na(ts$A68),]\n\n\n\n\nLeakage\nUrinary\nSexual\n\n\n\nLeakage problem at all time points for 934 participants who reported leakage problem at every time point.\nQ28: How big a problem, if any, has each of the following been for you during the last 4 weeks? Dripping or leaking urine.\n\nCodebar_tab2(tl$Time, tl$A28, \"Time\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\nUrinary problem at all time points for 934 participants who reported urinary problem at every time point.\nQ34: Overall, how big a problem has your urinary function been for you during the last 4 weeks?\n\nCodebar_tab2(tu$Time, tu$A34, \"Time\", \"Count\", \"Problem\", missing=F)\n\n\n\n\n\n\nSexual problem at all time points for 890 participants who reported urinary problem at every time point.\nQ58: Overall, how big a problem has your sexual function or lack of sexual function been for you during the last 4 weeks?\n\nCodebar_tab2(ts$Time, ts$A68, \"Time\", \"Count\", \"Problem\", missing=F)\n\n\n\n\nBaseline only\n\nCodesprob0 =  ts[ts$Time==0,]\nbar_tab(sprob0$A68, \"Problem\", \"Count\", save=\"Figures/Figure3A.jpg\")\n\n\n\n\nTwelve months only\n\nCodesprob12 =  ts[ts$Time==12,]\nbar_tab(sprob12$A68, \"Problem\", \"Count\", save=\"Figures/Figure3B.jpg\")\n\n\n\n\n\n\n\nComparisons\nThese values are used in the discussion to compare with previous studies.\n\n\nLow-risk cancer\nMeans\nMedications and devices\n\n\n\nPercentage with low-risk cancer for participants with risk category reported (according to D’Amico classification)\n\nCodetmp = promwc[complete.cases(promwc$DAmico),]\nproc_freq(tmp, \"DAmico\")\n\n\n\n\n\n\nDAmico\nCount\nPercent\n\n\n\nLow\n48\n5.2%\n\n\nIntermediate\n256\n27.6%\n\n\nHigh\n625\n67.3%\n\n\nTotal\n929\n100.0%\n\n\n\n\n\n\n\n\nThe scores are skewed and median should be used instead of mean (as we have shown in Section 3), the means are reported here only to compare to previous work which may have used means.\nMean urinary score\n\nCodemean(uf$Uscore.12)\n\n[1] 76\n\n\nMean sexual function score\n\nCodemean(sf$Sscore.12)\n\n[1] 28\n\n\nThis excludes the unknown participants.\n\n\nBaseline erection quality\n\nCodetmp = sf[complete.cases(sf$A59.0),]\ntab = proc_freq(tmp, \"A59.0\")\ntab = set_header_labels(tab,A59.0=\"Erection quality\")\ntab\n\n\n\n\n\n\nErection quality\nCount\nPercent\n\n\n\nFirm enough for intercourse\n703\n58.6%\n\n\nFirm enough for masturbation and foreplay only\n287\n23.9%\n\n\nNot firm enough for any sexual activity\n107\n8.9%\n\n\nNone at all\n103\n8.6%\n\n\nTotal\n1,200\n100.0%\n\n\n\n\n\n\nOf the 703 with erections firm enough for intercourse at baseline, the erection quality and medication/device use at 12 months is\n\nCodebaseSuff = sf[sf$A59.0=='Firm enough for intercourse',]\ntmp = data.frame(\"Erection\"=baseSuff$A59.12, \"Assistance\"=baseSuff$Assist.12)\nproc_freq(tmp, \"Erection\", \"Assistance\", include.row_percent = F, include.column_percent = F, include.table_percent = F)\n\n\n\n\n\n\n\nErection\nAssistance\n\n\nNo\nYes\nTotal\n\n\n\n\nFirm enough for intercourse\n38\n74\n112\n\n\nFirm enough for masturbation and foreplay only\n41\n159\n200\n\n\nNot firm enough for any sexual activity\n31\n84\n115\n\n\nNone at all\n90\n186\n276\n\n\nTotal\n200\n503\n703\n\n\n\n\n\n\n\n\n\nParallel coordinate plots\nThese plots can show participant progress across time. Each line represents an individual participant with the colour corresponding the final outcome at 12 months.\n\nCodeu = w[!is.na(w$A23.0) & !is.na(w$A27.0) &\n      !is.na(w$A23.6) & !is.na(w$A27.6) &\n      !is.na(w$A23.12) & !is.na(w$A27.12),]\n\ns = w[!is.na(w$A59.0) & !is.na(w$A59.6) & !is.na(w$A59.12),]\n\n\n\n\nLeakage\nPad use\nErection quality\n\n\n\nQ23: Over the past 4 weeks, how often have you leaked urine?\n\nCodeplt = u |&gt;\n  pcp_select(A23.0, A23.12) |&gt;\n  pcp_scale() |&gt;\n  pcp_arrange(method=\"from-right\")|&gt;\n  ggplot(aes_pcp()) +\n  geom_pcp_boxes(boxwidth=0.1) +\n  geom_pcp(aes(colour = A23.12), alpha = 0.1, axiswidth = c(0,0)) +\n  guides(colour=guide_legend(override.aes = list(alpha=1))) +\n  geom_pcp_labels() +\n  scale_x_discrete(expand = expansion(add=0.15),\n                   labels=c(\"A23.0\" = \"Baseline leakage\",\n                            \"A23.12\" = \"Twelve month leakage\")) +\n  labs(x='Item', y='Proportion', color='Twelve month leakage') +\n  theme(legend.position=\"none\")\nplt\n\n\n\n\n\n\nQ27: How many pads per day did you usually use to control leakage during the last 4 weeks?\n\nCodeplt = u |&gt;\n  pcp_select(A27.0, A27.12) |&gt;\n  pcp_scale() |&gt;\n  pcp_arrange(method=\"from-right\")|&gt;\n  ggplot(aes_pcp()) +\n  geom_pcp_boxes(boxwidth=0.1) +\n  geom_pcp(aes(colour = A27.12), alpha = 0.1, axiswidth = c(0,0)) +\n  guides(colour=guide_legend(override.aes = list(alpha=1))) +\n  geom_pcp_labels() +\n  scale_x_discrete(expand = expansion(add=0.2),\n                   labels=c(\"A27.0\" = \"Baseline pad use\",\n                            \"A27.12\" = \"Twelve month pad use\")) +\n  labs(x='Item', y='Proportion', color='Twelve month pad use') +\n  theme(legend.position=\"none\")\nplt\n\n\n\n\n\n\nQ59: How would you describe the usual QUALITY of your erections during the last 4 weeks?\n\nCodeplt = s |&gt;\n  pcp_select(A59.0, A59.12) |&gt;\n  pcp_scale() |&gt;\n  pcp_arrange(method=\"from-right\")|&gt;\n  ggplot(aes_pcp()) +\n  geom_pcp_boxes(boxwidth=0.1) +\n  geom_pcp(aes(colour = A59.12), alpha = 0.1, axiswidth = c(0,0)) +\n  guides(colour=guide_legend(override.aes = list(alpha=1))) +\n  geom_pcp_labels() +\n  scale_x_discrete(expand = expansion(add=0.5),\n                   labels=c(\"A59.0\" = \"Baseline erections\",\n                            \"A59.12\" = \"Twelve month erections\")) +\n  labs(x='Item', y='Proportion', color='Twelve month erections') +\n  theme(legend.position=\"none\")\nplt\n\n\n\n\n\n\n\nMissing data\nCode for the multiple imputation is given here. Multiple imputation by chained equations was used. The coded question answers are treated as ordinal. Use of assistance is treated as binary. Age is treated as continuous and is given no transformation.\nThe percentage of participants with missing responses at different time points is summarised in the table below.\n\nCodedf_miss = data.frame(\n  \"Item\"=c(\"Age\", \n           \"A23\", \"A26\", \"A27\", \"A28\",\n           \"A57\", \"A58\", \"A59\", \"A60\", \"A64\", \"A68\",\n           \"Assist\",\n           \"Any\"),\n  \n  \"Baseline\"=c(\n    (length(w$Study_ID[is.na(w$Age)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A23.0)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A26.0)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A27.0)])/2030)*100, \n    (length(w$Study_ID[is.na(w$A28.0)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A57.0)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A58.0)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A59.0)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A60.0)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A64.0)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A68.0)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Assist.0)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Age) | is.na(w$A23.0) | is.na(w$A26.0) | \n                       is.na(w$A27.0) | is.na(w$A28.0) | is.na(w$A57.0) | \n                       is.na(w$A58.0) | is.na(w$A59.0) | is.na(w$A60.0) | \n                       is.na(w$A64.0) | is.na(w$A68.0) | is.na(w$Assist.0) \n                       ])/2030)*100\n  ),\n  \"Month 1\"=c(\n    (length(w$Study_ID[is.na(w$Age)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A23.1)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A26.1)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A27.1)])/2030)*100, \n    (length(w$Study_ID[is.na(w$A28.1)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A57.1)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A58.1)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A59.1)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A60.1)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A64.1)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A68.1)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Assist.1)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Age) | is.na(w$A23.1) | is.na(w$A26.1) | \n                       is.na(w$A27.1) | is.na(w$A28.1) | is.na(w$A57.1) | \n                       is.na(w$A58.1) | is.na(w$A59.1) | is.na(w$A60.1) | \n                       is.na(w$A64.1) | is.na(w$A68.1) | is.na(w$Assist.1)  \n                       ])/2030)*100\n  ),\n  \"Month 3\"=c(\n    (length(w$Study_ID[is.na(w$Age)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A23.3)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A26.3)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A27.3)])/2030)*100, \n    (length(w$Study_ID[is.na(w$A28.3)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A57.3)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A58.3)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A59.3)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A60.3)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A64.3)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A68.3)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Assist.3)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Age) | is.na(w$A23.3) | is.na(w$A26.3) | \n                       is.na(w$A27.3) | is.na(w$A28.3) | is.na(w$A57.3) | \n                       is.na(w$A58.3) | is.na(w$A59.3) | is.na(w$A60.3) | \n                       is.na(w$A64.3) | is.na(w$A68.3) | is.na(w$Assist.3) \n                       ])/2030)*100\n  ),\n  \"Month 6\"=c(\n    (length(w$Study_ID[is.na(w$Age)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A23.6)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A26.6)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A27.6)])/2030)*100, \n    (length(w$Study_ID[is.na(w$A28.6)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A57.6)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A58.6)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A59.6)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A60.6)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A64.6)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A68.6)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Assist.6)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Age) | is.na(w$A23.6) | is.na(w$A26.6) | \n                       is.na(w$A27.6) | is.na(w$A28.6) | is.na(w$A57.6) | \n                       is.na(w$A58.6) | is.na(w$A59.6) | is.na(w$A60.6) | \n                       is.na(w$A64.6) | is.na(w$A68.6) | is.na(w$Assist.6) \n                       ])/2030)*100\n  ),\n  \"Month 12\"=c(\n    (length(w$Study_ID[is.na(w$Age)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A23.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A26.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A27.12)])/2030)*100, \n    (length(w$Study_ID[is.na(w$A28.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A57.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A58.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A59.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A60.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A64.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A68.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Assist.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Age) | is.na(w$A23.12) | is.na(w$A26.12) | \n                       is.na(w$A27.12) | is.na(w$A28.12) | is.na(w$A57.12) | \n                       is.na(w$A58.12) | is.na(w$A59.12) | is.na(w$A60.12) | \n                       is.na(w$A64.12) | is.na(w$A68.12) | is.na(w$Assist.12) \n                       ])/2030)*100\n  ),\n  \"Any\"=c(\n    (length(w$Study_ID[is.na(w$Age) ])/2030)*100,\n    (length(w$Study_ID[is.na(w$A23.0) | is.na(w$A23.1) | is.na(w$A23.3)| \n                       is.na(w$A23.6) | is.na(w$A23.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A26.0) | is.na(w$A26.1) | is.na(w$A26.3)| \n                       is.na(w$A26.6) | is.na(w$A26.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A27.0) | is.na(w$A27.1) | is.na(w$A27.3)| \n                       is.na(w$A27.6) | is.na(w$A27.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A28.0) | is.na(w$A28.1) | is.na(w$A28.3)| \n                       is.na(w$A28.6) | is.na(w$A28.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A57.0) | is.na(w$A57.1) | is.na(w$A57.3)| \n                       is.na(w$A57.6) | is.na(w$A57.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A58.0) | is.na(w$A58.1) | is.na(w$A58.3)| \n                       is.na(w$A58.6) | is.na(w$A58.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A59.0) | is.na(w$A59.1) | is.na(w$A59.3)| \n                       is.na(w$A59.6) | is.na(w$A59.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A60.0) | is.na(w$A60.1) | is.na(w$A60.3)| \n                       is.na(w$A60.6) | is.na(w$A60.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A64.0) | is.na(w$A64.1) | is.na(w$A64.3)| \n                       is.na(w$A64.6) | is.na(w$A64.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$A68.0) | is.na(w$A68.1) | is.na(w$A68.3)| \n                       is.na(w$A68.6) | is.na(w$A68.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Assist.0) | is.na(w$Assist.1) | is.na(w$Assist.3)| \n                       is.na(w$Assist.6) | is.na(w$Assist.12)])/2030)*100,\n    (length(w$Study_ID[\n                       is.na(w$Age) |\n                       is.na(w$A23.0) | is.na(w$A23.1) | is.na(w$A23.3)| \n                       is.na(w$A23.6) | is.na(w$A23.12) |\n                       is.na(w$A26.0) | is.na(w$A26.1) | is.na(w$A26.3)| \n                       is.na(w$A26.6) | is.na(w$A26.12) |\n                       is.na(w$A27.0) | is.na(w$A27.1) | is.na(w$A27.3)| \n                       is.na(w$A27.6) | is.na(w$A27.12) |\n                       is.na(w$A28.0) | is.na(w$A28.1) | is.na(w$A28.3)| \n                       is.na(w$A28.6) | is.na(w$A28.12) |\n                       is.na(w$A57.0) | is.na(w$A57.1) | is.na(w$A57.3)| \n                       is.na(w$A57.6) | is.na(w$A57.12) |\n                       is.na(w$A58.0) | is.na(w$A58.1) | is.na(w$A58.3)| \n                       is.na(w$A58.6) | is.na(w$A58.12) |\n                       is.na(w$A59.0) | is.na(w$A59.1) | is.na(w$A59.3)| \n                       is.na(w$A59.6) | is.na(w$A59.12) | \n                       is.na(w$A60.0) | is.na(w$A60.1) | is.na(w$A60.3)| \n                       is.na(w$A60.6) | is.na(w$A60.12) |\n                       is.na(w$A64.0) | is.na(w$A64.1) | is.na(w$A64.3)| \n                       is.na(w$A64.6) | is.na(w$A64.12) |\n                       is.na(w$A68.0) | is.na(w$A68.1) | is.na(w$A68.3)| \n                       is.na(w$A68.6) | is.na(w$A68.12) |\n                       is.na(w$Assist.0) | is.na(w$Assist.1) | is.na(w$Assist.3)| \n                       is.na(w$Assist.6) | is.na(w$Assist.12)\n                       ])/2030)*100\n  )\n  \n \n  \n)\nflextable(df_miss)\n\n\n\n\n\n\nItem\nBaseline\nMonth.1\nMonth.3\nMonth.6\nMonth.12\nAny\n\n\n\nAge\n3.60\n3.6\n3.6\n3.6\n3.6\n3.6\n\n\nA23\n0.39\n29.7\n30.3\n32.6\n29.9\n54.9\n\n\nA26\n0.39\n29.7\n30.1\n32.2\n29.8\n54.6\n\n\nA27\n0.20\n29.6\n30.0\n32.0\n29.6\n53.7\n\n\nA28\n0.89\n29.5\n30.3\n32.3\n29.4\n54.0\n\n\nA57\n3.45\n32.1\n33.6\n34.9\n33.3\n62.7\n\n\nA58\n5.07\n33.4\n34.6\n35.7\n34.4\n65.3\n\n\nA59\n2.61\n31.4\n32.6\n34.1\n31.6\n59.5\n\n\nA60\n2.51\n31.9\n32.1\n33.6\n31.0\n58.1\n\n\nA64\n2.27\n31.3\n31.7\n33.5\n30.7\n57.1\n\n\nA68\n1.87\n30.6\n31.2\n33.0\n30.6\n56.2\n\n\nAssist\n2.32\n31.0\n32.3\n34.2\n32.5\n59.3\n\n\nAny\n11.77\n36.1\n37.1\n38.5\n38.4\n70.7\n\n\n\n\n\n\nThe missing responses in the urinary incontinence and sexual function domains lead to missing domain scores. The percentage of participant with missing domain scores is shown below.\n\nCodedf_miss = data.frame(\n  \"Item\"=c(\"Urinary\", \"Sexual\", \"Either\"),\n  \n  \"Baseline\"=c(\n    (length(w$Study_ID[is.na(w$Uscore.0)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Sscore.0)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Uscore.0) | is.na(w$Sscore.0)])/2030)*100\n  ),\n  \"Month 1\"=c(\n    (length(w$Study_ID[is.na(w$Uscore.1)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Sscore.1)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Uscore.1) | is.na(w$Sscore.1)])/2030)*100\n  ),\n  \"Month 3\"=c(\n    (length(w$Study_ID[is.na(w$Uscore.3)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Sscore.3)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Uscore.3) | is.na(w$Sscore.3)])/2030)*100\n  ),\n  \"Month 6\"=c(\n    (length(w$Study_ID[is.na(w$Uscore.6)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Sscore.6)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Uscore.6) | is.na(w$Sscore.6)])/2030)*100\n  ),\n  \"Month 12\"=c(\n    (length(w$Study_ID[is.na(w$Uscore.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Sscore.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Uscore.12) | is.na(w$Sscore.12)])/2030)*100\n  ),\n  \"Any\"=c(\n    (length(w$Study_ID[is.na(w$Uscore.0) | is.na(w$Uscore.1) | is.na(w$Uscore.3)| \n                       is.na(w$Uscore.6) | is.na(w$Uscore.12)])/2030)*100,\n    (length(w$Study_ID[is.na(w$Sscore.0) | is.na(w$Sscore.1) | is.na(w$Sscore.3)| \n                       is.na(w$Sscore.6) | is.na(w$Sscore.12)])/2030)*100,\n\n    (length(w$Study_ID[\n                       is.na(w$Uscore.0) | is.na(w$Uscore.1) | is.na(w$Uscore.3)| \n                       is.na(w$Uscore.6) | is.na(w$Uscore.12) |\n                       is.na(w$Sscore.0) | is.na(w$Sscore.1) | is.na(w$Sscore.3)| \n                       is.na(w$Sscore.6) | is.na(w$Sscore.12)\n                       ])/2030)*100\n  )\n  \n \n  \n)\nflextable(df_miss)\n\n\n\n\n\n\nItem\nBaseline\nMonth.1\nMonth.3\nMonth.6\nMonth.12\nAny\n\n\n\nUrinary\n1.7\n30\n31\n33\n31\n57\n\n\nSexual\n3.8\n33\n34\n35\n33\n63\n\n\nEither\n5.2\n33\n34\n36\n35\n65\n\n\n\n\n\n\n\n\nMultiple imputation\nUrinary\nSexual\n\n\n\nThe missmap function in Amelia can be used to produce a missingness map.\n\nCodeset.seed(1)\n\n\n\nimp = subset(w, select=c(\n               'C23.0', 'C26.0', 'C27.0', 'C28.0',\n               'C57.0', 'C58.0', 'C59.0', 'C60.0', 'C64.0', 'C68.0',\n               'C23.1', 'C26.1', 'C27.1', 'C28.1',\n               'C57.1', 'C58.1', 'C59.1', 'C60.1', 'C64.1', 'C68.1',\n               'C23.3', 'C26.3', 'C27.3', 'C28.3',\n               'C57.3', 'C58.3', 'C59.3', 'C60.3', 'C64.3', 'C68.3',\n               'C23.6', 'C26.6', 'C27.6', 'C28.6',\n               'C57.6', 'C58.6', 'C59.6', 'C60.6', 'C64.6', 'C68.6',\n               'C23.12', 'C26.12', 'C27.12', 'C28.12',\n               'C57.12', 'C58.12', 'C59.12', 'C60.12', 'C64.12', 'C68.12',\n               'Assist.0', 'Assist.1', 'Assist.3', 'Assist.6', 'Assist.12',\n               'Age'\n\n))\n\ntoOrdinal &lt;- c('C23.0', 'C26.0', 'C27.0', 'C28.0',\n               'C57.0', 'C58.0', 'C59.0', 'C60.0', 'C64.0', 'C68.0',\n               'C23.1', 'C26.1', 'C27.1', 'C28.1',\n               'C57.1', 'C58.1', 'C59.1', 'C60.1', 'C64.1', 'C68.1',\n               'C23.3', 'C26.3', 'C27.3', 'C28.3',\n               'C57.3', 'C58.3', 'C59.3', 'C60.3', 'C64.3', 'C68.3',\n               'C23.6', 'C26.6', 'C27.6', 'C28.6',\n               'C57.6', 'C58.6', 'C59.6', 'C60.6', 'C64.6', 'C68.6',\n               'C23.12', 'C26.12', 'C27.12', 'C28.12',\n               'C57.12', 'C58.12', 'C59.12', 'C60.12', 'C64.12', 'C68.12'\n               )\nimp[toOrdinal] &lt;- lapply(imp[toOrdinal], ordered)\n\ntoFactors &lt;- c('Assist.0', 'Assist.1', 'Assist.3', 'Assist.6', 'Assist.12')\nimp[toFactors] &lt;- lapply(imp[toFactors], as.factor)\n\nmissmap(imp)\n\n\n\n\nThis shows that 25% of the total data is missing.\nMultiple imputation by chained equations using the domain responses with assistance use (yes/no) and participant age at surgery. As 25% of the data is missing, 25 imputed datasets are created.\n\nCode# This code block will take a long time to render (possibly days).\n# Use {r, MI1, eval=FALSE} after initial run to prevent this running. \n# After the first run the required files should already be saved.\n\nMI = mice(imp, m=25, seed=1, maxit=20)\nwrite.datlist(MI, 'MI/', type='csv')\n\n\n\n\n\nCodefolder1 = 'MI/MI'\nfolder2 = 'MI/UAll'\nfolder3 = 'MI/UBaselineLPFree'\nfolder4 = 'MI/UNBaselineLPFree'\n\nfor (i in 1:25){\n\n  mi_file1 = paste(folder1,'/__IMPDATA',i,'.csv', sep='')\n  mi_file2 = paste(folder2,'/MI__IMPDATA',i,'.csv', sep='')\n  mi_file3 = paste(folder3,'/MI__IMPDATA',i,'.csv', sep='')\n  mi_file4 = paste(folder4,'/MI__IMPDATA',i,'.csv', sep='')\n\n  mi_csv = read.csv(mi_file1, header=T)\n\n  mi_csv$LeakFree = ifelse(mi_csv$C23.12==100,1,0)\n  mi_csv$PadFree = ifelse(mi_csv$C27.12==100,1,0)\n  mi_csv$LeakPadFree = ifelse(mi_csv$C23.12==100 & mi_csv$C27.12==100,1,0)\n\n  mi_lpfree = subset(mi_csv, C23.0==100 & C27.0==100)\n  mi_nlpfree = subset(mi_csv, C23.0&lt;100 | C27.0&lt;100)\n\n  write.csv(mi_csv, mi_file2, row.names = F)\n  write.csv(mi_lpfree, mi_file3, row.names = F)\n  write.csv(mi_nlpfree, mi_file4, row.names = F)\n\n}\n\n\n\n\nAll\nBaseline leak and pad free\nBaseline not leak and pad free\n\n\n\nComplete case results from section 5.\n\nCodedf_tmp = data.frame(\"Type\"=c(\"Leak Free\", \"Pad Free\", \"Leak and Pad Free\"),\n                    \"Point\"=c(0.4459654,0.6512968,0.4200288 ),\n                    \"Lower\"=c(0.4200002,0.6258394,0.394319),\n                    \"Upper\"=c(0.4722289,0.6759191,0.4461801)\n                    )\n\nflextable(df_tmp)\n\n\n\n\n\n\nType\nPoint\nLower\nUpper\n\n\n\nLeak Free\n0.45\n0.42\n0.47\n\n\nPad Free\n0.65\n0.63\n0.68\n\n\nLeak and Pad Free\n0.42\n0.39\n0.45\n\n\n\n\n\n\nImputed results\n\nCodedataList = list(\n  read.csv('MI/UAll/MI__IMPDATA1.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA2.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA3.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA4.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA5.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA6.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA7.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA8.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA9.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA10.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA11.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA12.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA13.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA14.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA15.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA16.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA17.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA18.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA19.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA20.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA21.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA22.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA23.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA24.csv', header=T),\n  read.csv('MI/UAll/MI__IMPDATA25.csv', header=T)\n)\ndat = list2milist(dataList)\n\nLeakFree &lt;- with(dat, expr=prop_wald(LeakFree ~ 1))\nLeakFree &lt;- pool_prop_wilson(LeakFree)\nPadFree &lt;- with(dat, expr=prop_wald(PadFree ~ 1))\nPadFree &lt;- pool_prop_wilson(PadFree)\nLeakPadFree &lt;- with(dat, expr=prop_wald(LeakPadFree ~ 1))\nLeakPadFree &lt;- pool_prop_wilson(LeakPadFree)\n\n\n\ndf_tmp = data.frame(\"Type\"=c(\"Leak Free\", \"Pad Free\", \"Leak and Pad Free\"),\n                    \"Point\"=c(LeakFree[1],PadFree[1],LeakPadFree[1]),\n                    \"Lower\"=c(LeakFree[2],PadFree[2],LeakPadFree[2]),\n                    \"Upper\"=c(LeakFree[3],PadFree[3],LeakPadFree[3])\n                    )\n\nflextable(df_tmp)\n\n\n\n\n\n\nType\nPoint\nLower\nUpper\n\n\n\nLeak Free\n0.42\n0.39\n0.45\n\n\nPad Free\n0.62\n0.60\n0.65\n\n\nLeak and Pad Free\n0.36\n0.34\n0.39\n\n\n\n\n\n\nPlot comparing the complete case and imputed results\n\nCodeOutcome_order &lt;- c(                   \n                   'Leak and pad-free',\n                   'Pad free',\n                   'Leak free')\n\ndf1 &lt;- data.frame(Outcome=c(\n                            'Leak and pad-free',\n                            'Pad free',\n                            'Leak free'),\n                  Point=c(0.36144   ,0.62201,0.41980),\n                  Lower=c(0.33842   ,0.59763,0.39393    ),\n                  Upper=c(0.38511,0.64579,0.44613)\n                  )\n\ndf1$Group &lt;- \"Imputed\"\ndf2 &lt;- data.frame(Outcome=c(\n                            'Leak and pad-free',\n                            'Pad free',\n                            'Leak free'),\n                  Point=c(0.4200288 ,0.6512968  ,0.4459654  ),\n                  Lower=c(0.3943190 ,0.6258394  ,0.4200002  ),\n                  Upper=c(0.4461801 ,0.6759191  ,0.4722289)\n                  )\ndf2$Group &lt;- \"Complete\"\ndf = rbind(df1,df2)\ndf$Outcome = factor (df$Outcome, level=Outcome_order)\n\ndotCOLS = c(\"white\",\"white\")\nbarCOLS = c(\"darkorange2\",\"blue2\")\n\n\np &lt;- ggplot(df, aes(x=Outcome, y=Point, ymin=Lower, ymax=Upper,col=Group,fill=Group)) +\n  geom_linerange(size=5,position=position_dodge(width = 0.5)) +\n  geom_point(size=3, shape=20, colour=\"white\", stroke = 0.5,position=position_dodge(width = 0.5)) +\n  scale_fill_manual(values=dotCOLS)+\n  scale_color_manual(values=barCOLS)+\n  scale_x_discrete(name=\"Outcome\") +\n  scale_y_continuous(name=\"Proportion\", limits = c(0, 1)) +\n  coord_flip() +\n  theme_light()\np\n\n\n\n\n\n\nComplete case reuslts from section 5\n\nCodedf_tmp = data.frame(\"Type\"=c(\"Leak Free\", \"Pad Free\", \"Leak and Pad Free\"),\n                    \"Point\"=c(0.5055249,0.6979742   ,0.4815838  ),\n                    \"Lower\"=c(0.4758222 ,0.6700086      ,0.4519838      ),\n                    \"Upper\"=c(0.5351885,0.7245442,0.5113136)\n                    )\n\nflextable(df_tmp)\n\n\n\n\n\n\nType\nPoint\nLower\nUpper\n\n\n\nLeak Free\n0.51\n0.48\n0.54\n\n\nPad Free\n0.70\n0.67\n0.72\n\n\nLeak and Pad Free\n0.48\n0.45\n0.51\n\n\n\n\n\n\nImputed results\n\nCodedataList = list(\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA1.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA2.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA3.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA4.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA5.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA6.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA7.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA8.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA9.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA10.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA11.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA12.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA13.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA14.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA15.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA16.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA17.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA18.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA19.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA20.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA21.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA22.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA23.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA24.csv', header=T),\n  read.csv('MI/UBaselineLPFree/MI__IMPDATA25.csv', header=T)\n)\n\ndat = list2milist(dataList)\n\nLeakFree &lt;- with(dat, expr=prop_wald(LeakFree ~ 1))\nLeakFree &lt;- pool_prop_wilson(LeakFree)\nPadFree &lt;- with(dat, expr=prop_wald(PadFree ~ 1))\nPadFree &lt;- pool_prop_wilson(PadFree)\nLeakPadFree &lt;- with(dat, expr=prop_wald(LeakPadFree ~ 1))\nLeakPadFree &lt;- pool_prop_wilson(LeakPadFree)\n\ndf_tmp = data.frame(\"Type\"=c(\"Leak Free\", \"Pad Free\", \"Leak and Pad Free\"),\n                    \"Point\"=c(LeakFree[1],PadFree[1],LeakPadFree[1]),\n                    \"Lower\"=c(LeakFree[2],PadFree[2],LeakPadFree[2]),\n                    \"Upper\"=c(LeakFree[3],PadFree[3],LeakPadFree[3])\n                    )\n\nflextable(df_tmp)\n\n\n\n\n\n\nType\nPoint\nLower\nUpper\n\n\n\nLeak Free\n0.47\n0.44\n0.50\n\n\nPad Free\n0.66\n0.63\n0.69\n\n\nLeak and Pad Free\n0.41\n0.39\n0.44\n\n\n\n\n\n\nPlot comparing the complete case and imputed results\n\nCodeOutcome_order &lt;- c(                   \n                   'Leak and pad-free',\n                   'Pad free',\n                   'Leak free')\n\ndf1 &lt;- data.frame(Outcome=c(\n                            'Leak and pad-free',\n                            'Pad free',\n                            'Leak free'),\n                  Point=c(0.41182   ,0.65992    ,0.46808    ),\n                  Lower=c(0.38519       ,0.63207    ,0.43904    ),\n                  Upper=c(0.43898,0.68670,0.49734)\n                  )\n\ndf1$Group &lt;- \"Imputed\"\ndf2 &lt;- data.frame(Outcome=c(\n                            'Leak and pad-free',\n                            'Pad free',\n                            'Leak free'),\n                  Point=c(0.4815838     ,0.6979742      ,0.5055249  ),\n                  Lower=c(0.38519       ,0.63207    ,0.4758222  ),\n                  Upper=c(0.5113136,0.7245442,0.5351885)\n                  )\ndf2$Group &lt;- \"Complete\"\ndf = rbind(df1,df2)\ndf$Outcome = factor (df$Outcome, level=Outcome_order)\n\ndotCOLS = c(\"white\",\"white\")\nbarCOLS = c(\"darkorange2\",\"blue2\")\n\n\np &lt;- ggplot(df, aes(x=Outcome, y=Point, ymin=Lower, ymax=Upper,col=Group,fill=Group)) +\n  geom_linerange(size=5,position=position_dodge(width = 0.5)) +\n  geom_point(size=3, shape=20, colour=\"white\", stroke = 0.5,position=position_dodge(width = 0.5)) +\n  scale_fill_manual(values=dotCOLS)+\n  scale_color_manual(values=barCOLS)+\n  scale_x_discrete(name=\"Outcome\") +\n  scale_y_continuous(name=\"Proportion\", limits = c(0, 1)) +\n  coord_flip() +\n  theme_light()\np\n\n\n\n\n\n\nComplete case results from section 5\n\nCodedf_tmp = data.frame(\"Type\"=c(\"Leak Free\", \"Pad Free\", \"Leak and Pad Free\"),\n                    \"Point\"=c(0.2317881 ,0.4834437      ,0.1986755      ),\n                    \"Lower\"=c(0.1877452     ,0.4276456          ,0.157583       ),\n                    \"Upper\"=c(0.2825686,0.5396577,0.2473375)\n                    )\n\nflextable(df_tmp)\n\n\n\n\n\n\nType\nPoint\nLower\nUpper\n\n\n\nLeak Free\n0.23\n0.19\n0.28\n\n\nPad Free\n0.48\n0.43\n0.54\n\n\nLeak and Pad Free\n0.20\n0.16\n0.25\n\n\n\n\n\n\nImputed results\n\nCodedataList = list(\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA1.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA2.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA3.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA4.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA5.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA6.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA7.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA8.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA9.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA10.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA11.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA12.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA13.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA14.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA15.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA16.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA17.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA18.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA19.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA20.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA21.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA22.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA23.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA24.csv', header=T),\n  read.csv('MI/UNBaselineLPFree/MI__IMPDATA25.csv', header=T)\n)\n\ndat = list2milist(dataList)\n\nLeakFree &lt;- with(dat, expr=prop_wald(LeakFree ~ 1))\nLeakFree &lt;- pool_prop_wilson(LeakFree)\nPadFree &lt;- with(dat, expr=prop_wald(PadFree ~ 1))\nPadFree &lt;- pool_prop_wilson(PadFree)\nLeakPadFree &lt;- with(dat, expr=prop_wald(LeakPadFree ~ 1))\nLeakPadFree &lt;- pool_prop_wilson(LeakPadFree)\n\ndf_tmp = data.frame(\"Type\"=c(\"Leak Free\", \"Pad Free\", \"Leak and Pad Free\"),\n                    \"Point Estimate\"=c(LeakFree[1],PadFree[1],LeakPadFree[1]),\n                    \"Lower\"=c(LeakFree[2],PadFree[2],LeakPadFree[2]),\n                    \"Upper\"=c(LeakFree[3],PadFree[3],LeakPadFree[3])\n                    )\n\nflextable(df_tmp)\n\n\n\n\n\n\nType\nPoint.Estimate\nLower\nUpper\n\n\n\nLeak Free\n0.26\n0.22\n0.31\n\n\nPad Free\n0.50\n0.45\n0.56\n\n\nLeak and Pad Free\n0.20\n0.16\n0.24\n\n\n\n\n\n\nPlot comparing the complete case and imputed results\n\nCodeOutcome_order &lt;- c(                   \n                   'Leak and pad-free',\n                   'Pad free',\n                   'Leak free')\n\ndf1 &lt;- data.frame(Outcome=c(\n                            'Leak and pad-free',\n                            'Pad free',\n                            'Leak free'),\n                  Point=c(0.19748       ,0.49865    ,0.26270        ),\n                  Lower=c(0.15997       ,0.44946        ,0.21757        ),\n                  Upper=c(0.24127,0.54787,0.31344)\n                  )\n\ndf1$Group &lt;- \"Imputed\"\ndf2 &lt;- data.frame(Outcome=c(\n                            'Leak and pad-free',\n                            'Pad free',\n                            'Leak free'),\n                  Point=c(0.1986755     ,0.4834437  ,0.2317881      ),\n                  Lower=c(0.1575830     ,0.4276456      ,0.1877452  ),\n                  Upper=c(0.2473375,0.5396577,0.2825686)\n                  )\ndf2$Group &lt;- \"Complete\"\ndf = rbind(df1,df2)\ndf$Outcome = factor (df$Outcome, level=Outcome_order)\n\ndotCOLS = c(\"white\",\"white\")\nbarCOLS = c(\"darkorange2\",\"blue2\")\n\n\np &lt;- ggplot(df, aes(x=Outcome, y=Point, ymin=Lower, ymax=Upper,col=Group,fill=Group)) +\n  geom_linerange(size=5,position=position_dodge(width = 0.5)) +\n  geom_point(size=3, shape=20, colour=\"white\", stroke = 0.5,position=position_dodge(width = 0.5)) +\n  scale_fill_manual(values=dotCOLS)+\n  scale_color_manual(values=barCOLS)+\n  scale_x_discrete(name=\"Outcome\") +\n  scale_y_continuous(name=\"Proportion\", limits = c(0, 1)) +\n  coord_flip() +\n  theme_light()\np\n\n\n\n\n\n\n\n\n\n\nCodefolder1 = 'MI/MI'\nfolder2 = 'MI/SAll'\nfolder3 = 'MI/SBaselineNatAd'\nfolder4 = 'MI/SNBaselineNatAd'\n\nfor (i in 1:25){\n\n  mi_file1 = paste(folder1,'/__IMPDATA',i,'.csv', sep='')\n  mi_file2 = paste(folder2,'/MI__IMPDATA',i,'.csv', sep='')\n  mi_file3 = paste(folder3,'/MI__IMPDATA',i,'.csv', sep='')\n  mi_file4 = paste(folder4,'/MI__IMPDATA',i,'.csv', sep='')\n\n  mi_csv = read.csv(mi_file1, header=T)\n\n  mi_csv$UAd = ifelse(mi_csv$C59.12==100 & mi_csv$Assist.12=='No',1,0)\n  mi_csv$AAd = ifelse(mi_csv$C59.12==100 & mi_csv$Assist.12=='Yes',1,0)\n  mi_csv$Inad = ifelse(mi_csv$C59.12&lt;100,1,0)\n\n  mi_UnAd = subset(mi_csv, C59.0==100 & Assist.0=='No')\n  mi_NUnAd = subset(mi_csv, C59.0&lt;100 | Assist.0=='Yes')\n\n  write.csv(mi_csv, mi_file2, row.names = F)\n  write.csv(mi_UnAd, mi_file3, row.names = F)\n  write.csv(mi_NUnAd, mi_file4, row.names = F)\n\n}\n\n\n\n\nAll\nBaseline Natural erections\nNot baseline natural erections\n\n\n\nComplete case results from section 5\n\nCodedf_tmp = data.frame(\"Type\"=c(\"Unassisted Adequate\", \"Assisted adequate\", \"Inadequate\"),\n                    \"Point\"=c(  0.035 ,  0.0691667   ,  0.8958333     ),\n                    \"Lower\"=c(  0.0259968     ,  0.0561423    , 0.877268     ),\n                    \"Upper\"=c(   0.0469708  ,  0.0849406   , 0.9118724  )\n                    )\n\nflextable(df_tmp)\n\n\n\n\n\n\nType\nPoint\nLower\nUpper\n\n\n\nUnassisted Adequate\n0.035\n0.026\n0.047\n\n\nAssisted adequate\n0.069\n0.056\n0.085\n\n\nInadequate\n0.896\n0.877\n0.912\n\n\n\n\n\n\nImputed results\n\nCodedataList = list(\n  read.csv('MI/SAll/MI__IMPDATA1.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA2.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA3.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA4.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA5.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA6.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA7.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA8.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA9.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA10.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA11.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA12.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA13.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA14.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA15.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA16.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA17.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA18.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA19.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA20.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA21.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA22.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA23.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA24.csv', header=T),\n  read.csv('MI/SAll/MI__IMPDATA25.csv', header=T)\n)\ndat = list2milist(dataList)\n\nUAd &lt;- with(dat, expr=prop_wald(UAd ~ 1))\nUAd &lt;- pool_prop_wilson(UAd)\nAAd &lt;- with(dat, expr=prop_wald(AAd ~ 1))\nAAd &lt;- pool_prop_wilson(AAd)\nInad &lt;- with(dat, expr=prop_wald(Inad ~ 1))\nInad &lt;- pool_prop_wilson(Inad)\n\ndf_tmp = data.frame(\"Type\"=c(\"Unassisted Adequate\", \"Assisted adequate\", \"Inadequate\"),\n                    \"Point Estimate\"=c(UAd[1],AAd[1],Inad[1]),\n                    \"Lower\"=c(UAd[2],AAd[2],Inad[2]),\n                    \"Upper\"=c(UAd[3],AAd[3],Inad[3])\n                    )\n\nflextable(df_tmp)\n\n\n\n\n\n\nType\nPoint.Estimate\nLower\nUpper\n\n\n\nUnassisted Adequate\n0.038\n0.030\n0.049\n\n\nAssisted adequate\n0.066\n0.054\n0.079\n\n\nInadequate\n0.896\n0.880\n0.910\n\n\n\n\n\n\nPlot comparing the complete case and imputed results\n\nCodeOutcome_order &lt;- c(                   \n                   'Inadequate',\n                   'Assisted adequate',\n                   'Unassisted adequate')\n\ndf1 &lt;- data.frame(Outcome=c(                   \n                   'Inadequate',\n                   'Assisted adequate',\n                   'Unassisted adequate'),\n                  Point=c(0.89697       ,0.06824        ,0.03480        ),\n                  Lower=c(0.87990       ,0.05602            ,0.02520            ),\n                  Upper=c(0.91185,0.08288,0.04788)\n                  )\n\ndf1$Group &lt;- \"Imputed\"\ndf2 &lt;- data.frame(Outcome=c(                   \n                   'Inadequate',\n                   'Assisted adequate',\n                   'Unassisted adequate'),\n                  Point=c(0.89697       ,0.06824        ,0.03480        ),\n                  Lower=c(0.87990       ,0.05602        ,0.02520        ),\n                  Upper=c(0.91185,0.08288,0.04788)\n                  )\ndf2$Group &lt;- \"Complete\"\ndf = rbind(df1,df2)\ndf$Outcome = factor (df$Outcome, level=Outcome_order)\n\ndotCOLS = c(\"white\",\"white\")\nbarCOLS = c(\"darkorange2\",\"blue2\")\n\n\np &lt;- ggplot(df, aes(x=Outcome, y=Point, ymin=Lower, ymax=Upper,col=Group,fill=Group)) +\n  geom_linerange(size=5,position=position_dodge(width = 0.5)) +\n  geom_point(size=3, shape=20, colour=\"white\", stroke = 0.5,position=position_dodge(width = 0.5)) +\n  scale_fill_manual(values=dotCOLS)+\n  scale_color_manual(values=barCOLS)+\n  scale_x_discrete(name=\"Outcome\") +\n  scale_y_continuous(name=\"Proportion\", limits = c(0, 1)) +\n  coord_flip() +\n  theme_light()\np\n\n\n\n\n\n\nComplete case results from section 5\n\nCodedf_tmp = data.frame(\"Type\"=c(\"Unassisted Adequate\", \"Assisted adequate\", \"Inadequate\"),\n                    \"Point\"=c( 0.0587302      ,  0.1079365   , 0.8333333       ),\n                    \"Lower\"=c( 0.0429062       ,  0.0860392   , 0.80223  ),\n                    \"Upper\"=c(  0.0799028   ,   0.1345861  , 0.8603963  )\n                    )\n\nflextable(df_tmp)\n\n\n\n\n\n\nType\nPoint\nLower\nUpper\n\n\n\nUnassisted Adequate\n0.059\n0.043\n0.08\n\n\nAssisted adequate\n0.108\n0.086\n0.13\n\n\nInadequate\n0.833\n0.802\n0.86\n\n\n\n\n\n\nImputed results\n\nCodedataList = list(\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA1.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA2.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA3.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA4.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA5.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA6.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA7.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA8.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA9.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA10.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA11.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA12.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA13.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA14.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA15.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA16.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA17.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA18.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA19.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA20.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA21.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA22.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA23.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA24.csv', header=T),\n  read.csv('MI/SBaselineNatAd/MI__IMPDATA25.csv', header=T)\n)\n\ndat = list2milist(dataList)\n\nUAd &lt;- with(dat, expr=prop_wald(UAd ~ 1))\nUAd &lt;- pool_prop_wilson(UAd)\nAAd &lt;- with(dat, expr=prop_wald(AAd ~ 1))\nAAd &lt;- pool_prop_wilson(AAd)\nInad &lt;- with(dat, expr=prop_wald(Inad ~ 1))\nInad &lt;- pool_prop_wilson(Inad)\n\ndf_tmp = data.frame(\"Type\"=c(\"Unassisted Adequate\", \"Assisted adequate\", \"Inadequate\"),\n                    \"Point Estimate\"=c(UAd[1],AAd[1],Inad[1]),\n                    \"Lower\"=c(UAd[2],AAd[2],Inad[2]),\n                    \"Upper\"=c(UAd[3],AAd[3],Inad[3])\n                    )\n\nflextable(df_tmp)\n\n\n\n\n\n\nType\nPoint.Estimate\nLower\nUpper\n\n\n\nUnassisted Adequate\n0.052\n0.039\n0.069\n\n\nAssisted adequate\n0.096\n0.077\n0.120\n\n\nInadequate\n0.852\n0.824\n0.875\n\n\n\n\n\n\nPlot comparing the complete case and imputed results\n\nCodeOutcome_order &lt;- c(                   \n                   'Inadequate',\n                   'Assisted adequate',\n                   'Unassisted adequate')\n\ndf1 &lt;- data.frame(Outcome=c(                   \n                   'Inadequate',\n                   'Assisted adequate',\n                   'Unassisted adequate'),\n                  Point=c(0.85174       ,0.09949        ,0.04877        ),\n                  Lower=c(0.82548       ,0.08032                    ,0.03547                ),\n                  Upper=c(0.87466,0.12263,0.06670)\n                  )\n\ndf1$Group &lt;- \"Imputed\"\ndf2 &lt;- data.frame(Outcome=c(                   \n                   'Inadequate',\n                   'Assisted adequate',\n                   'Unassisted adequate'),\n                  Point=c(0.8333333     ,0.1079365      ,0.0587302  ),\n                  Lower=c(0.8022300         ,0.0860392          ,0.0429062          ),\n                  Upper=c(0.8603963,0.1345861,0.0799028)\n                  )\ndf2$Group &lt;- \"Complete\"\ndf = rbind(df1,df2)\ndf$Outcome = factor (df$Outcome, level=Outcome_order)\n\ndotCOLS = c(\"white\",\"white\")\nbarCOLS = c(\"darkorange2\",\"blue2\")\n\n\np &lt;- ggplot(df, aes(x=Outcome, y=Point, ymin=Lower, ymax=Upper,col=Group,fill=Group)) +\n  geom_linerange(size=5,position=position_dodge(width = 0.5)) +\n  geom_point(size=3, shape=20, colour=\"white\", stroke = 0.5,position=position_dodge(width = 0.5)) +\n  scale_fill_manual(values=dotCOLS)+\n  scale_color_manual(values=barCOLS)+\n  scale_x_discrete(name=\"Outcome\") +\n  scale_y_continuous(name=\"Proportion\", limits = c(0, 1)) +\n  coord_flip() +\n  theme_light()\np\n\n\n\n\n\n\nComplete case results from section 5\n\nCodedf_tmp = data.frame(\"Type\"=c(\"Unassisted Adequate\", \"Assisted adequate\", \"Inadequate\"),\n                    \"Point\"=c( 0.0087719      ,  0.0263158       , 0.9649123           ),\n                    \"Lower\"=c( 0.0037525           ,  0.0160114   , 0.9464269    ),\n                    \"Upper\"=c( 0.0203682   ,   0.0429621  , 0.9771731  )\n                    )\n\nflextable(df_tmp)\n\n\n\n\n\n\nType\nPoint\nLower\nUpper\n\n\n\nUnassisted Adequate\n0.0088\n0.0038\n0.020\n\n\nAssisted adequate\n0.0263\n0.0160\n0.043\n\n\nInadequate\n0.9649\n0.9464\n0.977\n\n\n\n\n\n\nImputed results\n\nCodedataList = list(\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA1.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA2.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA3.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA4.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA5.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA6.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA7.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA8.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA9.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA10.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA11.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA12.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA13.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA14.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA15.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA16.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA17.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA18.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA19.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA20.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA21.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA22.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA23.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA24.csv', header=T),\n  read.csv('MI/SNBaselineNatAd/MI__IMPDATA25.csv', header=T)\n)\n\ndat = list2milist(dataList)\n\nUAd &lt;- with(dat, expr=prop_wald(UAd ~ 1))\nUAd &lt;- pool_prop_wilson(UAd)\nAAd &lt;- with(dat, expr=prop_wald(AAd ~ 1))\nAAd &lt;- pool_prop_wilson(AAd)\nInad &lt;- with(dat, expr=prop_wald(Inad ~ 1))\nInad &lt;- pool_prop_wilson(Inad)\n\ndf_tmp = data.frame(\"Type\"=c(\"Unassisted Adequate\", \"Assisted adequate\", \"Inadequate\"),\n                    \"Point Estimate\"=c(UAd[1],AAd[1],Inad[1]),\n                    \"Lower\"=c(UAd[2],AAd[2],Inad[2]),\n                    \"Upper\"=c(UAd[3],AAd[3],Inad[3])\n                    )\n\nflextable(df_tmp)\n\n\n\n\n\n\nType\nPoint.Estimate\nLower\nUpper\n\n\n\nUnassisted Adequate\n0.024\n0.015\n0.038\n\n\nAssisted adequate\n0.034\n0.023\n0.051\n\n\nInadequate\n0.942\n0.923\n0.957\n\n\n\n\n\n\nPlot comparing the complete case and imputed results\n\nCodeOutcome_order &lt;- c(                   \n                   'Inadequate',\n                   'Assisted adequate',\n                   'Unassisted adequate')\n\ndf1 &lt;- data.frame(Outcome=c(                   \n                   'Inadequate',\n                   'Assisted adequate',\n                   'Unassisted adequate'),\n                  Point=c(0.94404       ,0.03571            ,0.02026            ),\n                  Lower=c(0.92177       ,0.02424                        ,0.01027                ),\n                  Upper=c(0.96024,0.05231,0.03958)\n                  )\n\ndf1$Group &lt;- \"Imputed\"\ndf2 &lt;- data.frame(Outcome=c(                   \n                   'Inadequate',\n                   'Assisted adequate',\n                   'Unassisted adequate'),\n                  Point=c(0.9649123     ,0.0263158      ,0.0087719      ),\n                  Lower=c(0.9464269         ,0.0160114              ,0.0037525              ),\n                  Upper=c(0.9771731 ,0.0429621,0.0203682)\n                  )\ndf2$Group &lt;- \"Complete\"\ndf = rbind(df1,df2)\ndf$Outcome = factor (df$Outcome, level=Outcome_order)\n\ndotCOLS = c(\"white\",\"white\")\nbarCOLS = c(\"darkorange2\",\"blue2\")\n\n\np &lt;- ggplot(df, aes(x=Outcome, y=Point, ymin=Lower, ymax=Upper,col=Group,fill=Group)) +\n  geom_linerange(size=5,position=position_dodge(width = 0.5)) +\n  geom_point(size=3, shape=20, colour=\"white\", stroke = 0.5,position=position_dodge(width = 0.5)) +\n  scale_fill_manual(values=dotCOLS)+\n  scale_color_manual(values=barCOLS)+\n  scale_x_discrete(name=\"Outcome\") +\n  scale_y_continuous(name=\"Proportion\", limits = c(0, 1)) +\n  coord_flip() +\n  theme_light()\np\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nAllaire, J., Xie, Y., McPherson, J., et al. (2022) Rmarkdown: Dynamic Documents for r. Available at: https://github.com/rstudio/rmarkdown.\n\n\nGagolewski, M. (2021) Stringi: Fast and Portable Character String Processing in r. Available at: https://stringi.gagolewski.com/.\n\n\nGohel, D. and Skintzos, P. (2023) Flextable: Functions for Tabular Reporting. Available at: https://CRAN.R-project.org/package=flextable.\n\n\nHarrell Jr, F. E. (2022) Hmisc: Harrell Miscellaneous. Available at: https://CRAN.R-project.org/package=Hmisc.\n\n\nHenry, L. and Wickham, H. (2023) Rlang: Functions for Base Types and Core r and ’Tidyverse’ Features. Available at: https://CRAN.R-project.org/package=rlang.\n\n\nHeymans, M. (2022) Miceafter: Data and Statistical Analyses After Multiple Imputation. Available at: https://CRAN.R-project.org/package=miceafter.\n\n\nHofmann, H., VanderPlas, S. and Ge, Y. (2022) Ggpcp: Parallel Coordinate Plots in the ’Ggplot2’ Framework. Available at: https://CRAN.R-project.org/package=ggpcp.\n\n\nHonaker, J., King, G. and Blackwell, M. (2011) Amelia II: A program for missing data. Journal of Statistical Software, 45, 1–47. Available at: https://www.jstatsoft.org/v45/i07/.\n\n\nOoms, J. (2022) Gifski: Highest Quality GIF Encoder. Available at: https://CRAN.R-project.org/package=gifski.\n\n\nPedersen, T. L. (2022) Patchwork: The Composer of Plots. Available at: https://CRAN.R-project.org/package=patchwork.\n\n\nPedersen, T. L. and Robinson, D. (2022) Gganimate: A Grammar of Animated Graphics. Available at: https://CRAN.R-project.org/package=gganimate.\n\n\nR Core Team (2021) R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. Available at: https://www.R-project.org/.\n\n\nRobitzsch, A. and Grund, S. (2022) Miceadds: Some Additional Multiple Imputation Functions, Especially for ’Mice’. Available at: https://CRAN.R-project.org/package=miceadds.\n\n\nvan Buuren, S. and Groothuis-Oudshoorn, K. (2011) mice: Multivariate imputation by chained equations in r. Journal of Statistical Software, 45, 1–67. DOI: 10.18637/jss.v045.i03.\n\n\nWei, J. T., Dunn, R. L., Litwin, M. S., et al. (2000) Development and validation of the expanded prostate cancer index composite (EPIC) for comprehensive assessment of health-related quality of life in men with prostate cancer. Urology, 56, 899–905. Elsevier.\n\n\nWickham, H. (2016) Ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York. Available at: https://ggplot2.tidyverse.org.\n\n\nWickham, H., François, R., Henry, L., et al. (2022) Dplyr: A Grammar of Data Manipulation. Available at: https://CRAN.R-project.org/package=dplyr.\n\n\nXie, Y. (2014) Knitr: A comprehensive tool for reproducible research in R. In Implementing Reproducible Computational Research (eds. V. Stodden, F. Leisch, and R. D. Peng). Chapman; Hall/CRC. Available at: http://www.crcpress.com/product/isbn/9781466561595.\n\n\nXie, Y., Allaire, J. J. and Grolemund, G. (2018) R Markdown: The Definitive Guide. Boca Raton, Florida: Chapman; Hall/CRC. Available at: https://bookdown.org/yihui/rmarkdown.\n\n\nXie, Y., Dervieux, C. and Riederer, E. (2020) R Markdown Cookbook. Boca Raton, Florida: Chapman; Hall/CRC. Available at: https://bookdown.org/yihui/rmarkdown-cookbook.\n\n\nZhu, H. (2021) kableExtra: Construct Complex Table with ’Kable’ and Pipe Syntax. Available at: https://CRAN.R-project.org/package=kableExtra."
  }
]